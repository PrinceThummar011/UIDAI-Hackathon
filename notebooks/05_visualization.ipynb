{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4357287d",
   "metadata": {},
   "source": [
    "# 05: Visualization Dashboard - UIDAI Hackathon PS-1\n",
    "\n",
    "**Predictive Analysis of Aadhaar Update Demand**\n",
    "\n",
    "This notebook creates publication-ready visualizations using **sampled data** to prevent memory issues.\n",
    "\n",
    "## Strategy:\n",
    "- Work with small data samples\n",
    "- Create static plots only\n",
    "- Save figures immediately\n",
    "- Clear memory after each section\n",
    "- Use try-except blocks for robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a284b9fe",
   "metadata": {},
   "source": [
    "## 1. Setup & Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0eccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for figures\n",
    "output_dir = Path('../outputs/figures')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Output directory created: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b9d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory management function\n",
    "def clear_memory():\n",
    "    \"\"\"Close all plots and run garbage collection\"\"\"\n",
    "    plt.close('all')\n",
    "    gc.collect()\n",
    "    \n",
    "def save_and_clear(filename, fig=None):\n",
    "    \"\"\"Save figure and clear memory\"\"\"\n",
    "    if fig is not None:\n",
    "        fig.savefig(output_dir / filename, bbox_inches='tight', dpi=150)\n",
    "    else:\n",
    "        plt.savefig(output_dir / filename, bbox_inches='tight', dpi=150)\n",
    "    print(f\"  → Saved: {filename}\")\n",
    "    clear_memory()\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb6bef",
   "metadata": {},
   "source": [
    "## 2. Load Data Efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature matrix sample (10k rows)\n",
    "print(\"Loading feature matrix sample...\")\n",
    "feature_matrix = pd.read_csv('../outputs/results/feature_matrix_sample.csv')\n",
    "\n",
    "# Convert date columns\n",
    "date_cols = [col for col in feature_matrix.columns if 'date' in col.lower() or 'time' in col.lower()]\n",
    "for col in date_cols:\n",
    "    try:\n",
    "        feature_matrix[col] = pd.to_datetime(feature_matrix[col])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"  Shape: {feature_matrix.shape}\")\n",
    "print(f\"  Memory: {feature_matrix.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"✓ Feature matrix loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16df838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions (sample if needed)\n",
    "print(\"\\nLoading predictions...\")\n",
    "try:\n",
    "    predictions = pd.read_csv('../outputs/results/predictions.csv')\n",
    "    \n",
    "    # Sample if too large\n",
    "    if len(predictions) > 100000:\n",
    "        predictions = predictions.sample(n=100000, random_state=42)\n",
    "        print(f\"  Sampled to 100k rows\")\n",
    "    \n",
    "    # Convert date columns\n",
    "    for col in predictions.columns:\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\n",
    "            try:\n",
    "                predictions[col] = pd.to_datetime(predictions[col])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"  Shape: {predictions.shape}\")\n",
    "    print(f\"  Memory: {predictions.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(\"✓ Predictions loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"  ⚠ Predictions file not found, will skip related visualizations\")\n",
    "    predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16725bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load regional classification\n",
    "print(\"\\nLoading regional classification...\")\n",
    "try:\n",
    "    regional_data = pd.read_csv('../outputs/results/regional_classification.csv')\n",
    "    print(f\"  Shape: {regional_data.shape}\")\n",
    "    print(f\"  Memory: {regional_data.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(\"✓ Regional data loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"  ⚠ Regional classification file not found, will skip related visualizations\")\n",
    "    regional_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3288c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load additional result files\n",
    "print(\"\\nLoading additional result files...\")\n",
    "try:\n",
    "    feature_importance = pd.read_csv('../outputs/results/feature_importance.csv')\n",
    "    print(f\"  Feature importance: {feature_importance.shape}\")\n",
    "except:\n",
    "    feature_importance = None\n",
    "    print(\"  ⚠ Feature importance not found\")\n",
    "\n",
    "try:\n",
    "    model_comparison = pd.read_csv('../outputs/results/model_comparison.csv')\n",
    "    print(f\"  Model comparison: {model_comparison.shape}\")\n",
    "except:\n",
    "    model_comparison = None\n",
    "    print(\"  ⚠ Model comparison not found\")\n",
    "\n",
    "print(\"\\n✓ Data loading complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db404cac",
   "metadata": {},
   "source": [
    "## 3. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e14179",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating temporal analysis...\")\n",
    "\n",
    "try:\n",
    "    # Find date and demand columns\n",
    "    date_col = None\n",
    "    demand_col = None\n",
    "    \n",
    "    # Look for date columns\n",
    "    for col in feature_matrix.columns:\n",
    "        if 'date' in col.lower() and feature_matrix[col].dtype == 'datetime64[ns]':\n",
    "            date_col = col\n",
    "            break\n",
    "    \n",
    "    # Look for demand/update columns\n",
    "    for col in feature_matrix.columns:\n",
    "        if any(word in col.lower() for word in ['demand', 'update', 'count', 'volume']):\n",
    "            if pd.api.types.is_numeric_dtype(feature_matrix[col]):\n",
    "                demand_col = col\n",
    "                break\n",
    "    \n",
    "    if date_col and demand_col:\n",
    "        # Prepare data\n",
    "        temp_data = feature_matrix[[date_col, demand_col]].copy()\n",
    "        temp_data = temp_data.dropna()\n",
    "        temp_data = temp_data.sort_values(date_col)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle('Temporal Analysis of Aadhaar Update Demand', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Daily trend (last 90 days)\n",
    "        recent_data = temp_data.tail(min(90, len(temp_data)))\n",
    "        axes[0, 0].plot(recent_data[date_col], recent_data[demand_col], linewidth=1.5, color='#2E86AB')\n",
    "        axes[0, 0].set_title('Daily Update Demand (Last 90 Days)')\n",
    "        axes[0, 0].set_xlabel('Date')\n",
    "        axes[0, 0].set_ylabel('Update Demand')\n",
    "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Monthly aggregation\n",
    "        temp_data['month'] = temp_data[date_col].dt.to_period('M')\n",
    "        monthly = temp_data.groupby('month')[demand_col].sum().reset_index()\n",
    "        monthly['month'] = monthly['month'].astype(str)\n",
    "        axes[0, 1].bar(range(len(monthly)), monthly[demand_col], color='#A23B72', alpha=0.7)\n",
    "        axes[0, 1].set_title('Monthly Aggregated Updates')\n",
    "        axes[0, 1].set_xlabel('Month')\n",
    "        axes[0, 1].set_ylabel('Total Updates')\n",
    "        axes[0, 1].set_xticks(range(len(monthly)))\n",
    "        axes[0, 1].set_xticklabels(monthly['month'], rotation=45, ha='right')\n",
    "        axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Plot 3: Day of week pattern\n",
    "        temp_data['dayofweek'] = temp_data[date_col].dt.day_name()\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        axes[1, 0].boxplot([temp_data[temp_data['dayofweek'] == day][demand_col].values \n",
    "                            for day in day_order if day in temp_data['dayofweek'].values],\n",
    "                           labels=[d[:3] for d in day_order if d in temp_data['dayofweek'].values],\n",
    "                           patch_artist=True,\n",
    "                           boxprops=dict(facecolor='#F18F01', alpha=0.6))\n",
    "        axes[1, 0].set_title('Day of Week Pattern')\n",
    "        axes[1, 0].set_xlabel('Day')\n",
    "        axes[1, 0].set_ylabel('Update Demand')\n",
    "        axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Plot 4: Month-wise summary\n",
    "        temp_data['month_num'] = temp_data[date_col].dt.month\n",
    "        monthly_avg = temp_data.groupby('month_num')[demand_col].mean().reset_index()\n",
    "        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        axes[1, 1].bar(monthly_avg['month_num'], monthly_avg[demand_col], color='#06A77D', alpha=0.7)\n",
    "        axes[1, 1].set_title('Average Demand by Month')\n",
    "        axes[1, 1].set_xlabel('Month')\n",
    "        axes[1, 1].set_ylabel('Average Demand')\n",
    "        axes[1, 1].set_xticks(monthly_avg['month_num'])\n",
    "        axes[1, 1].set_xticklabels([month_names[m-1] for m in monthly_avg['month_num']], rotation=45)\n",
    "        axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_and_clear('temporal_analysis.png', fig)\n",
    "        print(\"✓ Temporal analysis complete\")\n",
    "    else:\n",
    "        print(f\"  ⚠ Required columns not found (date: {date_col}, demand: {demand_col})\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error in temporal analysis: {str(e)}\")\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb42799",
   "metadata": {},
   "source": [
    "## 4. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating geographic analysis...\")\n",
    "\n",
    "try:\n",
    "    # Find geographic columns\n",
    "    state_col = None\n",
    "    district_col = None\n",
    "    \n",
    "    for col in feature_matrix.columns:\n",
    "        if 'state' in col.lower():\n",
    "            state_col = col\n",
    "        if 'district' in col.lower():\n",
    "            district_col = col\n",
    "    \n",
    "    if state_col:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle('Geographic Analysis of Aadhaar Updates', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Top 15 states\n",
    "        state_counts = feature_matrix[state_col].value_counts().head(15)\n",
    "        axes[0, 0].barh(range(len(state_counts)), state_counts.values, color='#2E86AB', alpha=0.7)\n",
    "        axes[0, 0].set_yticks(range(len(state_counts)))\n",
    "        axes[0, 0].set_yticklabels(state_counts.index)\n",
    "        axes[0, 0].set_title('Top 15 States by Update Volume')\n",
    "        axes[0, 0].set_xlabel('Number of Updates')\n",
    "        axes[0, 0].invert_yaxis()\n",
    "        axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Plot 2: Top 15 districts (if available)\n",
    "        if district_col:\n",
    "            district_counts = feature_matrix[district_col].value_counts().head(15)\n",
    "            axes[0, 1].barh(range(len(district_counts)), district_counts.values, color='#A23B72', alpha=0.7)\n",
    "            axes[0, 1].set_yticks(range(len(district_counts)))\n",
    "            axes[0, 1].set_yticklabels(district_counts.index)\n",
    "            axes[0, 1].set_title('Top 15 Districts by Update Volume')\n",
    "            axes[0, 1].set_xlabel('Number of Updates')\n",
    "            axes[0, 1].invert_yaxis()\n",
    "            axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'District data not available', \n",
    "                           ha='center', va='center', fontsize=12)\n",
    "            axes[0, 1].axis('off')\n",
    "        \n",
    "        # Plot 3: State-wise update rate\n",
    "        state_stats = feature_matrix.groupby(state_col).size().sort_values(ascending=True).tail(15)\n",
    "        axes[1, 0].barh(range(len(state_stats)), state_stats.values, color='#F18F01', alpha=0.7)\n",
    "        axes[1, 0].set_yticks(range(len(state_stats)))\n",
    "        axes[1, 0].set_yticklabels(state_stats.index)\n",
    "        axes[1, 0].set_title('State-wise Update Distribution')\n",
    "        axes[1, 0].set_xlabel('Update Count')\n",
    "        axes[1, 0].invert_yaxis()\n",
    "        axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Plot 4: Geographic summary statistics\n",
    "        total_states = feature_matrix[state_col].nunique()\n",
    "        total_updates = len(feature_matrix)\n",
    "        avg_per_state = total_updates / total_states if total_states > 0 else 0\n",
    "        \n",
    "        summary_text = f\"Geographic Summary\\n\\n\"\n",
    "        summary_text += f\"Total States: {total_states}\\n\"\n",
    "        if district_col:\n",
    "            summary_text += f\"Total Districts: {feature_matrix[district_col].nunique()}\\n\"\n",
    "        summary_text += f\"Total Updates: {total_updates:,}\\n\"\n",
    "        summary_text += f\"Avg Updates/State: {avg_per_state:.0f}\\n\\n\"\n",
    "        summary_text += f\"Top State: {state_counts.index[0]}\\n\"\n",
    "        summary_text += f\"Top State Updates: {state_counts.values[0]:,}\"\n",
    "        \n",
    "        axes[1, 1].text(0.1, 0.5, summary_text, fontsize=10, \n",
    "                       verticalalignment='center', family='monospace',\n",
    "                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_and_clear('geographic_analysis.png', fig)\n",
    "        print(\"✓ Geographic analysis complete\")\n",
    "    else:\n",
    "        print(f\"  ⚠ State column not found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error in geographic analysis: {str(e)}\")\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df2079",
   "metadata": {},
   "source": [
    "## 5. Demand Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e052764",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating demand forecast visualization...\")\n",
    "\n",
    "try:\n",
    "    if predictions is not None:\n",
    "        # Find actual and predicted columns\n",
    "        actual_col = None\n",
    "        predicted_col = None\n",
    "        date_col = None\n",
    "        \n",
    "        for col in predictions.columns:\n",
    "            if 'actual' in col.lower() or 'true' in col.lower():\n",
    "                actual_col = col\n",
    "            elif 'predict' in col.lower() or 'forecast' in col.lower():\n",
    "                predicted_col = col\n",
    "            elif 'date' in col.lower() or 'time' in col.lower():\n",
    "                if predictions[col].dtype == 'datetime64[ns]':\n",
    "                    date_col = col\n",
    "        \n",
    "        if actual_col and predicted_col:\n",
    "            # Calculate metrics\n",
    "            pred_data = predictions[[actual_col, predicted_col]].dropna()\n",
    "            rmse = np.sqrt(np.mean((pred_data[actual_col] - pred_data[predicted_col])**2))\n",
    "            mae = np.mean(np.abs(pred_data[actual_col] - pred_data[predicted_col]))\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
    "            fig.suptitle('Demand Forecast Performance', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Plot 1: Actual vs Predicted scatter\n",
    "            sample_size = min(5000, len(pred_data))\n",
    "            sample_data = pred_data.sample(n=sample_size, random_state=42)\n",
    "            \n",
    "            axes[0].scatter(sample_data[actual_col], sample_data[predicted_col], \n",
    "                          alpha=0.3, s=20, color='#2E86AB')\n",
    "            \n",
    "            # Add diagonal line\n",
    "            min_val = min(sample_data[actual_col].min(), sample_data[predicted_col].min())\n",
    "            max_val = max(sample_data[actual_col].max(), sample_data[predicted_col].max())\n",
    "            axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "            \n",
    "            axes[0].set_title(f'Actual vs Predicted (RMSE: {rmse:.2f}, MAE: {mae:.2f})')\n",
    "            axes[0].set_xlabel('Actual Demand')\n",
    "            axes[0].set_ylabel('Predicted Demand')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 2: Time series (if date available)\n",
    "            if date_col:\n",
    "                time_data = predictions[[date_col, actual_col, predicted_col]].dropna()\n",
    "                time_data = time_data.sort_values(date_col).tail(min(30, len(time_data)))\n",
    "                \n",
    "                axes[1].plot(time_data[date_col], time_data[actual_col], \n",
    "                           marker='o', linewidth=2, label='Actual', color='#2E86AB')\n",
    "                axes[1].plot(time_data[date_col], time_data[predicted_col], \n",
    "                           marker='s', linewidth=2, label='Predicted', color='#F18F01')\n",
    "                axes[1].set_title('Actual vs Predicted (Last 30 Days)')\n",
    "                axes[1].set_xlabel('Date')\n",
    "                axes[1].set_ylabel('Demand')\n",
    "                axes[1].legend()\n",
    "                axes[1].tick_params(axis='x', rotation=45)\n",
    "                axes[1].grid(True, alpha=0.3)\n",
    "            else:\n",
    "                # Show residuals histogram instead\n",
    "                residuals = pred_data[actual_col] - pred_data[predicted_col]\n",
    "                axes[1].hist(residuals, bins=50, color='#A23B72', alpha=0.7, edgecolor='black')\n",
    "                axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "                axes[1].set_title('Prediction Error Distribution')\n",
    "                axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
    "                axes[1].set_ylabel('Frequency')\n",
    "                axes[1].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            save_and_clear('demand_forecast.png', fig)\n",
    "            print(\"✓ Demand forecast visualization complete\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Required columns not found (actual: {actual_col}, predicted: {predicted_col})\")\n",
    "    else:\n",
    "        print(\"  ⚠ Predictions data not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error in demand forecast: {str(e)}\")\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b42324",
   "metadata": {},
   "source": [
    "## 6. Regional Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7202cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating regional classification visualization...\")\n",
    "\n",
    "try:\n",
    "    if regional_data is not None:\n",
    "        # Find cluster column\n",
    "        cluster_col = None\n",
    "        for col in regional_data.columns:\n",
    "            if 'cluster' in col.lower() or 'class' in col.lower() or 'category' in col.lower():\n",
    "                cluster_col = col\n",
    "                break\n",
    "        \n",
    "        if cluster_col:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "            fig.suptitle('Regional Classification Analysis', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Plot 1: Cluster distribution (pie chart)\n",
    "            cluster_counts = regional_data[cluster_col].value_counts()\n",
    "            colors = plt.cm.Set3(range(len(cluster_counts)))\n",
    "            axes[0, 0].pie(cluster_counts.values, labels=cluster_counts.index, autopct='%1.1f%%',\n",
    "                          colors=colors, startangle=90)\n",
    "            axes[0, 0].set_title('Cluster Distribution')\n",
    "            \n",
    "            # Plot 2: Cluster sizes (bar chart)\n",
    "            axes[0, 1].bar(range(len(cluster_counts)), cluster_counts.values, \n",
    "                          color=colors, alpha=0.7, edgecolor='black')\n",
    "            axes[0, 1].set_xticks(range(len(cluster_counts)))\n",
    "            axes[0, 1].set_xticklabels(cluster_counts.index)\n",
    "            axes[0, 1].set_title('Regions per Cluster')\n",
    "            axes[0, 1].set_xlabel('Cluster')\n",
    "            axes[0, 1].set_ylabel('Number of Regions')\n",
    "            axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Plot 3: Cluster characteristics (if numeric columns available)\n",
    "            numeric_cols = regional_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            if cluster_col in numeric_cols:\n",
    "                numeric_cols.remove(cluster_col)\n",
    "            \n",
    "            if len(numeric_cols) >= 2:\n",
    "                # Take first 2-3 numeric columns\n",
    "                feature_cols = numeric_cols[:min(3, len(numeric_cols))]\n",
    "                cluster_means = regional_data.groupby(cluster_col)[feature_cols].mean()\n",
    "                \n",
    "                x = np.arange(len(cluster_means.index))\n",
    "                width = 0.25\n",
    "                \n",
    "                for i, col in enumerate(feature_cols):\n",
    "                    axes[1, 0].bar(x + i*width, cluster_means[col], width, \n",
    "                                 label=col[:20], alpha=0.7)\n",
    "                \n",
    "                axes[1, 0].set_xlabel('Cluster')\n",
    "                axes[1, 0].set_ylabel('Average Value')\n",
    "                axes[1, 0].set_title('Cluster Characteristics')\n",
    "                axes[1, 0].set_xticks(x + width)\n",
    "                axes[1, 0].set_xticklabels(cluster_means.index)\n",
    "                axes[1, 0].legend()\n",
    "                axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "            else:\n",
    "                axes[1, 0].text(0.5, 0.5, 'Insufficient numeric features\\nfor cluster analysis', \n",
    "                               ha='center', va='center', fontsize=12)\n",
    "                axes[1, 0].axis('off')\n",
    "            \n",
    "            # Plot 4: Sample regions per cluster\n",
    "            summary_text = \"Sample Regions per Cluster\\n\\n\"\n",
    "            region_col = None\n",
    "            for col in regional_data.columns:\n",
    "                if 'region' in col.lower() or 'state' in col.lower() or 'district' in col.lower():\n",
    "                    region_col = col\n",
    "                    break\n",
    "            \n",
    "            if region_col:\n",
    "                for cluster in sorted(regional_data[cluster_col].unique()):\n",
    "                    cluster_regions = regional_data[regional_data[cluster_col] == cluster][region_col].head(3).tolist()\n",
    "                    summary_text += f\"Cluster {cluster}:\\n\"\n",
    "                    for region in cluster_regions:\n",
    "                        summary_text += f\"  • {str(region)[:25]}\\n\"\n",
    "                    summary_text += \"\\n\"\n",
    "            else:\n",
    "                summary_text += f\"Total Clusters: {len(cluster_counts)}\\n\"\n",
    "                summary_text += f\"Total Regions: {len(regional_data)}\\n\"\n",
    "                summary_text += f\"Largest Cluster: {cluster_counts.index[0]}\\n\"\n",
    "                summary_text += f\"Regions in Largest: {cluster_counts.values[0]}\"\n",
    "            \n",
    "            axes[1, 1].text(0.05, 0.95, summary_text, fontsize=9, \n",
    "                           verticalalignment='top', family='monospace',\n",
    "                           bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "            axes[1, 1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            save_and_clear('regional_clusters.png', fig)\n",
    "            print(\"✓ Regional classification visualization complete\")\n",
    "        else:\n",
    "            print(\"  ⚠ Cluster column not found\")\n",
    "    else:\n",
    "        print(\"  ⚠ Regional data not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error in regional classification: {str(e)}\")\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739246ba",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e54827",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating feature importance visualization...\")\n",
    "\n",
    "try:\n",
    "    if feature_importance is not None:\n",
    "        # Find feature and importance columns\n",
    "        feature_col = None\n",
    "        importance_col = None\n",
    "        \n",
    "        for col in feature_importance.columns:\n",
    "            if 'feature' in col.lower() or 'name' in col.lower():\n",
    "                feature_col = col\n",
    "            elif 'importance' in col.lower() or 'score' in col.lower() or 'weight' in col.lower():\n",
    "                importance_col = col\n",
    "        \n",
    "        if feature_col and importance_col:\n",
    "            # Get top 20 features\n",
    "            top_features = feature_importance.nlargest(20, importance_col)\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            \n",
    "            # Create color map based on importance\n",
    "            colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(top_features)))\n",
    "            \n",
    "            bars = ax.barh(range(len(top_features)), top_features[importance_col].values, \n",
    "                          color=colors, alpha=0.8, edgecolor='black')\n",
    "            \n",
    "            ax.set_yticks(range(len(top_features)))\n",
    "            ax.set_yticklabels(top_features[feature_col].values)\n",
    "            ax.set_xlabel('Importance Score', fontsize=12)\n",
    "            ax.set_title('Top 20 Feature Importance', fontsize=14, fontweight='bold', pad=20)\n",
    "            ax.invert_yaxis()\n",
    "            ax.grid(True, alpha=0.3, axis='x')\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, (bar, val) in enumerate(zip(bars, top_features[importance_col].values)):\n",
    "                ax.text(val, i, f' {val:.4f}', va='center', fontsize=8)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            save_and_clear('feature_analysis.png', fig)\n",
    "            print(\"✓ Feature importance visualization complete\")\n",
    "        else:\n",
    "            print(f\"  ⚠ Required columns not found (feature: {feature_col}, importance: {importance_col})\")\n",
    "    else:\n",
    "        print(\"  ⚠ Feature importance data not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error in feature importance: {str(e)}\")\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbef810",
   "metadata": {},
   "source": [
    "## 8. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ecafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating model performance visualization...\")\n",
    "\n",
    "try:\n",
    "    if model_comparison is not None:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Find model name column\n",
    "        model_col = None\n",
    "        for col in model_comparison.columns:\n",
    "            if 'model' in col.lower() or 'name' in col.lower():\n",
    "                model_col = col\n",
    "                break\n",
    "        \n",
    "        if model_col is None and len(model_comparison.columns) > 0:\n",
    "            model_col = model_comparison.columns[0]\n",
    "        \n",
    "        # Plot 1: RMSE comparison\n",
    "        rmse_cols = [col for col in model_comparison.columns if 'rmse' in col.lower()]\n",
    "        if rmse_cols and model_col:\n",
    "            rmse_col = rmse_cols[0]\n",
    "            axes[0, 0].bar(range(len(model_comparison)), model_comparison[rmse_col], \n",
    "                          color='#2E86AB', alpha=0.7, edgecolor='black')\n",
    "            axes[0, 0].set_xticks(range(len(model_comparison)))\n",
    "            axes[0, 0].set_xticklabels(model_comparison[model_col], rotation=45, ha='right')\n",
    "            axes[0, 0].set_title('RMSE Comparison (Lower is Better)')\n",
    "            axes[0, 0].set_ylabel('RMSE')\n",
    "            axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "        else:\n",
    "            axes[0, 0].text(0.5, 0.5, 'RMSE data not available', ha='center', va='center')\n",
    "            axes[0, 0].axis('off')\n",
    "        \n",
    "        # Plot 2: R² comparison\n",
    "        r2_cols = [col for col in model_comparison.columns if 'r2' in col.lower() or 'r_squared' in col.lower()]\n",
    "        if r2_cols and model_col:\n",
    "            r2_col = r2_cols[0]\n",
    "            axes[0, 1].bar(range(len(model_comparison)), model_comparison[r2_col], \n",
    "                          color='#06A77D', alpha=0.7, edgecolor='black')\n",
    "            axes[0, 1].set_xticks(range(len(model_comparison)))\n",
    "            axes[0, 1].set_xticklabels(model_comparison[model_col], rotation=45, ha='right')\n",
    "            axes[0, 1].set_title('R² Score Comparison (Higher is Better)')\n",
    "            axes[0, 1].set_ylabel('R² Score')\n",
    "            axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "        else:\n",
    "            axes[0, 1].text(0.5, 0.5, 'R² data not available', ha='center', va='center')\n",
    "            axes[0, 1].axis('off')\n",
    "        \n",
    "        # Plot 3: Residuals (if predictions available)\n",
    "        if predictions is not None:\n",
    "            actual_col = None\n",
    "            predicted_col = None\n",
    "            for col in predictions.columns:\n",
    "                if 'actual' in col.lower():\n",
    "                    actual_col = col\n",
    "                elif 'predict' in col.lower():\n",
    "                    predicted_col = col\n",
    "            \n",
    "            if actual_col and predicted_col:\n",
    "                residuals = predictions[actual_col] - predictions[predicted_col]\n",
    "                residuals = residuals.dropna()\n",
    "                axes[1, 0].hist(residuals, bins=50, color='#A23B72', alpha=0.7, edgecolor='black')\n",
    "                axes[1, 0].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "                axes[1, 0].set_title('Residual Distribution')\n",
    "                axes[1, 0].set_xlabel('Residual (Actual - Predicted)')\n",
    "                axes[1, 0].set_ylabel('Frequency')\n",
    "                axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "            else:\n",
    "                axes[1, 0].text(0.5, 0.5, 'Residual data not available', ha='center', va='center')\n",
    "                axes[1, 0].axis('off')\n",
    "        else:\n",
    "            axes[1, 0].text(0.5, 0.5, 'Prediction data not available', ha='center', va='center')\n",
    "            axes[1, 0].axis('off')\n",
    "        \n",
    "        # Plot 4: Model summary\n",
    "        if model_col:\n",
    "            summary_text = \"Model Performance Summary\\n\\n\"\n",
    "            summary_text += f\"Models Compared: {len(model_comparison)}\\n\\n\"\n",
    "            \n",
    "            if rmse_cols:\n",
    "                best_model_idx = model_comparison[rmse_cols[0]].idxmin()\n",
    "                summary_text += f\"Best Model (RMSE):\\n\"\n",
    "                summary_text += f\"  {model_comparison.loc[best_model_idx, model_col]}\\n\"\n",
    "                summary_text += f\"  RMSE: {model_comparison.loc[best_model_idx, rmse_cols[0]]:.4f}\\n\\n\"\n",
    "            \n",
    "            if r2_cols:\n",
    "                best_model_idx = model_comparison[r2_cols[0]].idxmax()\n",
    "                summary_text += f\"Best Model (R²):\\n\"\n",
    "                summary_text += f\"  {model_comparison.loc[best_model_idx, model_col]}\\n\"\n",
    "                summary_text += f\"  R²: {model_comparison.loc[best_model_idx, r2_cols[0]]:.4f}\"\n",
    "            \n",
    "            axes[1, 1].text(0.1, 0.5, summary_text, fontsize=10, \n",
    "                           verticalalignment='center', family='monospace',\n",
    "                           bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "            axes[1, 1].axis('off')\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'Model summary not available', ha='center', va='center')\n",
    "            axes[1, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_and_clear('model_performance.png', fig)\n",
    "        print(\"✓ Model performance visualization complete\")\n",
    "    else:\n",
    "        print(\"  ⚠ Model comparison data not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error in model performance: {str(e)}\")\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b65ea9",
   "metadata": {},
   "source": [
    "## 9. Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c260f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating executive summary visualization...\")\n",
    "\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create infographic-style summary\n",
    "    fig.suptitle('UIDAI Hackathon PS-1: Executive Summary', \n",
    "                fontsize=16, fontweight='bold', y=0.95)\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    metrics = []\n",
    "    \n",
    "    # Metric 1: Total data points\n",
    "    metrics.append({\n",
    "        'title': 'Total Records',\n",
    "        'value': f\"{len(feature_matrix):,}\",\n",
    "        'subtitle': 'Data Points Analyzed'\n",
    "    })\n",
    "    \n",
    "    # Metric 2: Geographic coverage\n",
    "    state_col = None\n",
    "    for col in feature_matrix.columns:\n",
    "        if 'state' in col.lower():\n",
    "            state_col = col\n",
    "            break\n",
    "    if state_col:\n",
    "        metrics.append({\n",
    "            'title': 'States Covered',\n",
    "            'value': f\"{feature_matrix[state_col].nunique()}\",\n",
    "            'subtitle': 'Geographic Regions'\n",
    "        })\n",
    "    \n",
    "    # Metric 3: Model performance\n",
    "    if predictions is not None:\n",
    "        actual_col = None\n",
    "        predicted_col = None\n",
    "        for col in predictions.columns:\n",
    "            if 'actual' in col.lower():\n",
    "                actual_col = col\n",
    "            elif 'predict' in col.lower():\n",
    "                predicted_col = col\n",
    "        \n",
    "        if actual_col and predicted_col:\n",
    "            pred_data = predictions[[actual_col, predicted_col]].dropna()\n",
    "            rmse = np.sqrt(np.mean((pred_data[actual_col] - pred_data[predicted_col])**2))\n",
    "            metrics.append({\n",
    "                'title': 'Model RMSE',\n",
    "                'value': f\"{rmse:.2f}\",\n",
    "                'subtitle': 'Prediction Error'\n",
    "            })\n",
    "    \n",
    "    # Metric 4: Features analyzed\n",
    "    if feature_importance is not None:\n",
    "        metrics.append({\n",
    "            'title': 'Features',\n",
    "            'value': f\"{len(feature_importance)}\",\n",
    "            'subtitle': 'Variables Analyzed'\n",
    "        })\n",
    "    \n",
    "    # Metric 5: Regional clusters\n",
    "    if regional_data is not None:\n",
    "        cluster_col = None\n",
    "        for col in regional_data.columns:\n",
    "            if 'cluster' in col.lower():\n",
    "                cluster_col = col\n",
    "                break\n",
    "        if cluster_col:\n",
    "            metrics.append({\n",
    "                'title': 'Clusters',\n",
    "                'value': f\"{regional_data[cluster_col].nunique()}\",\n",
    "                'subtitle': 'Regional Groups'\n",
    "            })\n",
    "    \n",
    "    # Metric 6: Models compared\n",
    "    if model_comparison is not None:\n",
    "        metrics.append({\n",
    "            'title': 'Models Tested',\n",
    "            'value': f\"{len(model_comparison)}\",\n",
    "            'subtitle': 'ML Algorithms'\n",
    "        })\n",
    "    \n",
    "    # Layout metrics in grid\n",
    "    n_metrics = len(metrics)\n",
    "    cols = 3\n",
    "    rows = (n_metrics + cols - 1) // cols\n",
    "    \n",
    "    colors = ['#2E86AB', '#A23B72', '#F18F01', '#06A77D', '#C73E1D', '#6A4C93']\n",
    "    \n",
    "    for idx, metric in enumerate(metrics):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        \n",
    "        x = 0.15 + col * 0.30\n",
    "        y = 0.75 - row * 0.35\n",
    "        \n",
    "        # Draw card background\n",
    "        rect = plt.Rectangle((x-0.12, y-0.12), 0.24, 0.24, \n",
    "                            facecolor=colors[idx % len(colors)], \n",
    "                            alpha=0.15, transform=fig.transFigure)\n",
    "        fig.patches.append(rect)\n",
    "        \n",
    "        # Add text\n",
    "        fig.text(x, y+0.05, metric['title'], \n",
    "                fontsize=11, ha='center', weight='bold',\n",
    "                transform=fig.transFigure)\n",
    "        fig.text(x, y, metric['value'], \n",
    "                fontsize=24, ha='center', weight='bold',\n",
    "                color=colors[idx % len(colors)],\n",
    "                transform=fig.transFigure)\n",
    "        fig.text(x, y-0.06, metric['subtitle'], \n",
    "                fontsize=9, ha='center', style='italic',\n",
    "                transform=fig.transFigure)\n",
    "    \n",
    "    # Add footer\n",
    "    fig.text(0.5, 0.05, 'Predictive Analysis of Aadhaar Update Demand', \n",
    "            fontsize=10, ha='center', style='italic',\n",
    "            transform=fig.transFigure)\n",
    "    \n",
    "    save_and_clear('executive_summary.png', fig)\n",
    "    print(\"✓ Executive summary visualization complete\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  ✗ Error in executive summary: {str(e)}\")\n",
    "    clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970f776",
   "metadata": {},
   "source": [
    "## 10. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all generated figures\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VISUALIZATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "figure_files = list(output_dir.glob('*.png'))\n",
    "if figure_files:\n",
    "    print(f\"\\n✓ Generated {len(figure_files)} visualizations:\")\n",
    "    for fig_file in sorted(figure_files):\n",
    "        file_size = fig_file.stat().st_size / 1024  # KB\n",
    "        print(f\"  • {fig_file.name} ({file_size:.1f} KB)\")\n",
    "    print(f\"\\nAll figures saved to: {output_dir}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No figures were generated\")\n",
    "\n",
    "# Final memory cleanup\n",
    "clear_memory()\n",
    "print(\"\\n✓ Memory cleaned\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
