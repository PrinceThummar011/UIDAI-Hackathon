{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c605dd65",
   "metadata": {},
   "source": [
    "# UIDAI Hackathon PS-1: Data Exploration\n",
    "## Predictive Analysis of Aadhaar Update Demand\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on three Aadhaar datasets:\n",
    "1. **Enrolment Data**: New Aadhaar enrollments by age group\n",
    "2. **Demographic Data**: Demographic update requests\n",
    "3. **Biometric Data**: Biometric update requests\n",
    "\n",
    "### Objectives:\n",
    "- Load and consolidate all CSV files from each dataset\n",
    "- Perform data quality checks\n",
    "- Generate statistical summaries\n",
    "- Identify patterns and insights\n",
    "- Save metadata for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768b8bf",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6066894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.3\n",
      "NumPy version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6c2d4a",
   "metadata": {},
   "source": [
    "## 2. Define Data Paths and Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45cbd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Paths:\n",
      "Enrolment: /home/prince/Desktop/UIDAI Hackathon/dataset/api_data_aadhar_enrolment\n",
      "Demographic: /home/prince/Desktop/UIDAI Hackathon/dataset/api_data_aadhar_demographic\n",
      "Biometric: /home/prince/Desktop/UIDAI Hackathon/dataset/api_data_aadhar_biometric\n",
      "Output: /home/prince/Desktop/UIDAI Hackathon/outputs/results\n"
     ]
    }
   ],
   "source": [
    "# Define base path\n",
    "BASE_PATH = Path('/home/prince/Desktop/UIDAI Hackathon')\n",
    "DATASET_PATH = BASE_PATH / 'dataset'\n",
    "\n",
    "# Define paths for each dataset\n",
    "ENROLMENT_PATH = DATASET_PATH / 'api_data_aadhar_enrolment'\n",
    "DEMOGRAPHIC_PATH = DATASET_PATH / 'api_data_aadhar_demographic'\n",
    "BIOMETRIC_PATH = DATASET_PATH / 'api_data_aadhar_biometric'\n",
    "\n",
    "# Output path\n",
    "OUTPUT_PATH = BASE_PATH / 'outputs' / 'results'\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Data Paths:\")\n",
    "print(f\"Enrolment: {ENROLMENT_PATH}\")\n",
    "print(f\"Demographic: {DEMOGRAPHIC_PATH}\")\n",
    "print(f\"Biometric: {BIOMETRIC_PATH}\")\n",
    "print(f\"Output: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24038f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_and_concatenate_csvs(folder_path, dataset_name):\n",
    "    \"\"\"\n",
    "    Load all CSV files from a folder and concatenate them into a single DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    folder_path: Path to the folder containing CSV files\n",
    "    dataset_name: Name of the dataset for logging\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: Concatenated data from all CSV files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        csv_files = sorted(glob.glob(str(folder_path / '*.csv')))\n",
    "        \n",
    "        if not csv_files:\n",
    "            print(f\"No CSV files found in {folder_path}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n{dataset_name} - Found {len(csv_files)} CSV files:\")\n",
    "        for file in csv_files:\n",
    "            print(f\"  - {Path(file).name}\")\n",
    "        \n",
    "        # Load and concatenate all CSV files\n",
    "        dfs = []\n",
    "        for file in csv_files:\n",
    "            df = pd.read_csv(file)\n",
    "            dfs.append(df)\n",
    "            print(f\"  Loaded {Path(file).name}: {df.shape[0]:,} rows\")\n",
    "        \n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"\\n{dataset_name} - Total combined shape: {combined_df.shape}\")\n",
    "        print(f\"Total rows: {combined_df.shape[0]:,} | Total columns: {combined_df.shape[1]}\")\n",
    "        \n",
    "        return combined_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"Data loading function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b514af",
   "metadata": {},
   "source": [
    "## 3. Load All Datasets\n",
    "\n",
    "Loading and consolidating all CSV files from each dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55acd345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enrolment Data - Found 3 CSV files:\n",
      "  - api_data_aadhar_enrolment_0_500000.csv\n",
      "  - api_data_aadhar_enrolment_1000000_1006029.csv\n",
      "  - api_data_aadhar_enrolment_500000_1000000.csv\n",
      "  Loaded api_data_aadhar_enrolment_0_500000.csv: 500,000 rows\n",
      "  Loaded api_data_aadhar_enrolment_1000000_1006029.csv: 6,029 rows\n",
      "  Loaded api_data_aadhar_enrolment_500000_1000000.csv: 500,000 rows\n",
      "\n",
      "Enrolment Data - Total combined shape: (1006029, 7)\n",
      "Total rows: 1,006,029 | Total columns: 7\n"
     ]
    }
   ],
   "source": [
    "# Load Enrolment Data\n",
    "df_enrolment = load_and_concatenate_csvs(ENROLMENT_PATH, \"Enrolment Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750eaf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demographic Data - Found 5 CSV files:\n",
      "  - api_data_aadhar_demographic_0_500000.csv\n",
      "  - api_data_aadhar_demographic_1000000_1500000.csv\n",
      "  - api_data_aadhar_demographic_1500000_2000000.csv\n",
      "  - api_data_aadhar_demographic_2000000_2071700.csv\n",
      "  - api_data_aadhar_demographic_500000_1000000.csv\n",
      "  Loaded api_data_aadhar_demographic_0_500000.csv: 500,000 rows\n",
      "  Loaded api_data_aadhar_demographic_1000000_1500000.csv: 500,000 rows\n",
      "  Loaded api_data_aadhar_demographic_1500000_2000000.csv: 500,000 rows\n",
      "  Loaded api_data_aadhar_demographic_2000000_2071700.csv: 71,700 rows\n",
      "  Loaded api_data_aadhar_demographic_500000_1000000.csv: 500,000 rows\n",
      "\n",
      "Demographic Data - Total combined shape: (2071700, 6)\n",
      "Total rows: 2,071,700 | Total columns: 6\n"
     ]
    }
   ],
   "source": [
    "# Load Demographic Data\n",
    "df_demographic = load_and_concatenate_csvs(DEMOGRAPHIC_PATH, \"Demographic Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c1d132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Biometric Data - Found 4 CSV files:\n",
      "  - api_data_aadhar_biometric_0_500000.csv\n",
      "  - api_data_aadhar_biometric_1000000_1500000.csv\n",
      "  - api_data_aadhar_biometric_1500000_1861108.csv\n",
      "  - api_data_aadhar_biometric_500000_1000000.csv\n",
      "  Loaded api_data_aadhar_biometric_0_500000.csv: 500,000 rows\n",
      "  Loaded api_data_aadhar_biometric_1000000_1500000.csv: 500,000 rows\n",
      "  Loaded api_data_aadhar_biometric_1500000_1861108.csv: 361,108 rows\n",
      "  Loaded api_data_aadhar_biometric_500000_1000000.csv: 500,000 rows\n",
      "\n",
      "Biometric Data - Total combined shape: (1861108, 6)\n",
      "Total rows: 1,861,108 | Total columns: 6\n"
     ]
    }
   ],
   "source": [
    "# Load Biometric Data\n",
    "df_biometric = load_and_concatenate_csvs(BIOMETRIC_PATH, \"Biometric Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb9dd0",
   "metadata": {},
   "source": [
    "## 4. Basic Dataset Information\n",
    "\n",
    "### 4.1 Enrolment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2ec117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENROLMENT DATASET - BASIC INFORMATION\n",
      "================================================================================\n",
      "\n",
      "Shape: (1006029, 7)\n",
      "Rows: 1,006,029\n",
      "Columns: 7\n",
      "\n",
      "Column Names:\n",
      "['date', 'state', 'district', 'pincode', 'age_0_5', 'age_5_17', 'age_18_greater']\n",
      "\n",
      "Data Types:\n",
      "date              object\n",
      "state             object\n",
      "district          object\n",
      "pincode            int64\n",
      "age_0_5            int64\n",
      "age_5_17           int64\n",
      "age_18_greater     int64\n",
      "dtype: object\n",
      "\n",
      "Memory Usage:\n",
      "Index                  132\n",
      "date              59355711\n",
      "state             59166221\n",
      "district          58078418\n",
      "pincode            8048232\n",
      "age_0_5            8048232\n",
      "age_5_17           8048232\n",
      "age_18_greater     8048232\n",
      "dtype: int64\n",
      "\n",
      "Total Memory: 199.12 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ENROLMENT DATASET - BASIC INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nShape: {df_enrolment.shape}\")\n",
    "print(f\"Rows: {df_enrolment.shape[0]:,}\")\n",
    "print(f\"Columns: {df_enrolment.shape[1]}\")\n",
    "print(f\"\\nColumn Names:\\n{df_enrolment.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df_enrolment.dtypes)\n",
    "print(f\"\\nMemory Usage:\")\n",
    "print(df_enrolment.memory_usage(deep=True))\n",
    "print(f\"\\nTotal Memory: {df_enrolment.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd16ab0",
   "metadata": {},
   "source": [
    "### 4.2 Demographic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee6da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEMOGRAPHIC DATASET - BASIC INFORMATION\n",
      "================================================================================\n",
      "\n",
      "Shape: (2071700, 6)\n",
      "Rows: 2,071,700\n",
      "Columns: 6\n",
      "\n",
      "Column Names:\n",
      "['date', 'state', 'district', 'pincode', 'demo_age_5_17', 'demo_age_17_']\n",
      "\n",
      "Data Types:\n",
      "date             object\n",
      "state            object\n",
      "district         object\n",
      "pincode           int64\n",
      "demo_age_5_17     int64\n",
      "demo_age_17_      int64\n",
      "dtype: object\n",
      "\n",
      "Memory Usage:\n",
      "Index                  132\n",
      "date             122230300\n",
      "state            121916773\n",
      "district         120112391\n",
      "pincode           16573600\n",
      "demo_age_5_17     16573600\n",
      "demo_age_17_      16573600\n",
      "dtype: int64\n",
      "\n",
      "Total Memory: 394.80 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DEMOGRAPHIC DATASET - BASIC INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nShape: {df_demographic.shape}\")\n",
    "print(f\"Rows: {df_demographic.shape[0]:,}\")\n",
    "print(f\"Columns: {df_demographic.shape[1]}\")\n",
    "print(f\"\\nColumn Names:\\n{df_demographic.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df_demographic.dtypes)\n",
    "print(f\"\\nMemory Usage:\")\n",
    "print(df_demographic.memory_usage(deep=True))\n",
    "print(f\"\\nTotal Memory: {df_demographic.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa8ed9f",
   "metadata": {},
   "source": [
    "### 4.3 Biometric Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc54cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BIOMETRIC DATASET - BASIC INFORMATION\n",
      "================================================================================\n",
      "\n",
      "Shape: (1861108, 6)\n",
      "Rows: 1,861,108\n",
      "Columns: 6\n",
      "\n",
      "Column Names:\n",
      "['date', 'state', 'district', 'pincode', 'bio_age_5_17', 'bio_age_17_']\n",
      "\n",
      "Data Types:\n",
      "date            object\n",
      "state           object\n",
      "district        object\n",
      "pincode          int64\n",
      "bio_age_5_17     int64\n",
      "bio_age_17_      int64\n",
      "dtype: object\n",
      "\n",
      "Memory Usage:\n",
      "Index                 132\n",
      "date            109805372\n",
      "state           109513287\n",
      "district        107684220\n",
      "pincode          14888864\n",
      "bio_age_5_17     14888864\n",
      "bio_age_17_      14888864\n",
      "dtype: int64\n",
      "\n",
      "Total Memory: 354.45 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BIOMETRIC DATASET - BASIC INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nShape: {df_biometric.shape}\")\n",
    "print(f\"Rows: {df_biometric.shape[0]:,}\")\n",
    "print(f\"Columns: {df_biometric.shape[1]}\")\n",
    "print(f\"\\nColumn Names:\\n{df_biometric.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\")\n",
    "print(df_biometric.dtypes)\n",
    "print(f\"\\nMemory Usage:\")\n",
    "print(df_biometric.memory_usage(deep=True))\n",
    "print(f\"\\nTotal Memory: {df_biometric.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707574f7",
   "metadata": {},
   "source": [
    "## 5. Data Preview\n",
    "\n",
    "### 5.1 Enrolment Dataset - First and Last 10 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a91fc921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-03-2025</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>East Khasi Hills</td>\n",
       "      <td>793121</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560043</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Kanpur Nagar</td>\n",
       "      <td>208001</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>202133</td>\n",
       "      <td>62</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Bengaluru Urban</td>\n",
       "      <td>560016</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843331</td>\n",
       "      <td>20</td>\n",
       "      <td>49</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Sitamarhi</td>\n",
       "      <td>843330</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Bahraich</td>\n",
       "      <td>271865</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Firozabad</td>\n",
       "      <td>283204</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>09-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Purbi Champaran</td>\n",
       "      <td>845418</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          state          district  pincode  age_0_5  age_5_17  \\\n",
       "0  02-03-2025      Meghalaya  East Khasi Hills   793121       11        61   \n",
       "1  09-03-2025      Karnataka   Bengaluru Urban   560043       14        33   \n",
       "2  09-03-2025  Uttar Pradesh      Kanpur Nagar   208001       29        82   \n",
       "3  09-03-2025  Uttar Pradesh           Aligarh   202133       62        29   \n",
       "4  09-03-2025      Karnataka   Bengaluru Urban   560016       14        16   \n",
       "5  09-03-2025          Bihar         Sitamarhi   843331       20        49   \n",
       "6  09-03-2025          Bihar         Sitamarhi   843330       23        24   \n",
       "7  09-03-2025  Uttar Pradesh          Bahraich   271865       26        60   \n",
       "8  09-03-2025  Uttar Pradesh         Firozabad   283204       28        26   \n",
       "9  09-03-2025          Bihar   Purbi Champaran   845418       30        48   \n",
       "\n",
       "   age_18_greater  \n",
       "0              37  \n",
       "1              39  \n",
       "2              12  \n",
       "3              15  \n",
       "4              21  \n",
       "5              12  \n",
       "6              42  \n",
       "7              14  \n",
       "8              10  \n",
       "9              10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1006019</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500023</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006020</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500027</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006021</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500033</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006022</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500036</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006023</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500040</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006024</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500045</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006025</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500057</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006026</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500061</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006027</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500062</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006028</th>\n",
       "      <td>31-12-2025</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>500095</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date      state   district  pincode  age_0_5  age_5_17  \\\n",
       "1006019  31-12-2025  Telangana  Hyderabad   500023        9         9   \n",
       "1006020  31-12-2025  Telangana  Hyderabad   500027        6         4   \n",
       "1006021  31-12-2025  Telangana  Hyderabad   500033        4         0   \n",
       "1006022  31-12-2025  Telangana  Hyderabad   500036        6         2   \n",
       "1006023  31-12-2025  Telangana  Hyderabad   500040        2         1   \n",
       "1006024  31-12-2025  Telangana  Hyderabad   500045        4         5   \n",
       "1006025  31-12-2025  Telangana  Hyderabad   500057        0         2   \n",
       "1006026  31-12-2025  Telangana  Hyderabad   500061        4         2   \n",
       "1006027  31-12-2025  Telangana  Hyderabad   500062        1         4   \n",
       "1006028  31-12-2025  Telangana  Hyderabad   500095        0         1   \n",
       "\n",
       "         age_18_greater  \n",
       "1006019               0  \n",
       "1006020               0  \n",
       "1006021               0  \n",
       "1006022               0  \n",
       "1006023               0  \n",
       "1006024               1  \n",
       "1006025               0  \n",
       "1006026               0  \n",
       "1006027               0  \n",
       "1006028               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"First 10 rows:\")\n",
    "display(df_enrolment.head(10))\n",
    "print(\"\\nLast 10 rows:\")\n",
    "display(df_enrolment.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139c877",
   "metadata": {},
   "source": [
    "### 5.2 Demographic Dataset - First and Last 10 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72477a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Gorakhpur</td>\n",
       "      <td>273213</td>\n",
       "      <td>49</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Chittoor</td>\n",
       "      <td>517132</td>\n",
       "      <td>22</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Rajkot</td>\n",
       "      <td>360006</td>\n",
       "      <td>65</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Srikakulam</td>\n",
       "      <td>532484</td>\n",
       "      <td>24</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>Udaipur</td>\n",
       "      <td>313801</td>\n",
       "      <td>45</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>Sikar</td>\n",
       "      <td>332028</td>\n",
       "      <td>28</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Tumakuru</td>\n",
       "      <td>572201</td>\n",
       "      <td>88</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Gorakhpur</td>\n",
       "      <td>273211</td>\n",
       "      <td>61</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Kurnool</td>\n",
       "      <td>518313</td>\n",
       "      <td>83</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Paschim Medinipur</td>\n",
       "      <td>721148</td>\n",
       "      <td>13</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           state           district  pincode  demo_age_5_17  \\\n",
       "0  01-03-2025   Uttar Pradesh          Gorakhpur   273213             49   \n",
       "1  01-03-2025  Andhra Pradesh           Chittoor   517132             22   \n",
       "2  01-03-2025         Gujarat             Rajkot   360006             65   \n",
       "3  01-03-2025  Andhra Pradesh         Srikakulam   532484             24   \n",
       "4  01-03-2025       Rajasthan            Udaipur   313801             45   \n",
       "5  01-03-2025       Rajasthan              Sikar   332028             28   \n",
       "6  01-03-2025       Karnataka           Tumakuru   572201             88   \n",
       "7  01-03-2025   Uttar Pradesh          Gorakhpur   273211             61   \n",
       "8  01-03-2025  Andhra Pradesh            Kurnool   518313             83   \n",
       "9  01-03-2025     West Bengal  Paschim Medinipur   721148             13   \n",
       "\n",
       "   demo_age_17_  \n",
       "0           529  \n",
       "1           375  \n",
       "2           765  \n",
       "3           314  \n",
       "4           785  \n",
       "5           285  \n",
       "6           332  \n",
       "7           836  \n",
       "8           986  \n",
       "9           281  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2071690</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Deoria</td>\n",
       "      <td>274205</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071691</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Deoria</td>\n",
       "      <td>274705</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071692</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etah</td>\n",
       "      <td>207120</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071693</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etah</td>\n",
       "      <td>207125</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071694</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etah</td>\n",
       "      <td>207249</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071695</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etah</td>\n",
       "      <td>207250</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071696</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etah</td>\n",
       "      <td>207401</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071697</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etawah</td>\n",
       "      <td>206003</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071698</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etawah</td>\n",
       "      <td>206125</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071699</th>\n",
       "      <td>31-10-2025</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Etawah</td>\n",
       "      <td>206126</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date          state district  pincode  demo_age_5_17  \\\n",
       "2071690  31-10-2025  Uttar Pradesh   Deoria   274205              5   \n",
       "2071691  31-10-2025  Uttar Pradesh   Deoria   274705              3   \n",
       "2071692  31-10-2025  Uttar Pradesh     Etah   207120              7   \n",
       "2071693  31-10-2025  Uttar Pradesh     Etah   207125              3   \n",
       "2071694  31-10-2025  Uttar Pradesh     Etah   207249              1   \n",
       "2071695  31-10-2025  Uttar Pradesh     Etah   207250              2   \n",
       "2071696  31-10-2025  Uttar Pradesh     Etah   207401              1   \n",
       "2071697  31-10-2025  Uttar Pradesh   Etawah   206003              3   \n",
       "2071698  31-10-2025  Uttar Pradesh   Etawah   206125              1   \n",
       "2071699  31-10-2025  Uttar Pradesh   Etawah   206126              1   \n",
       "\n",
       "         demo_age_17_  \n",
       "2071690            20  \n",
       "2071691            11  \n",
       "2071692            31  \n",
       "2071693            19  \n",
       "2071694            51  \n",
       "2071695            17  \n",
       "2071696            27  \n",
       "2071697            10  \n",
       "2071698            25  \n",
       "2071699            25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"First 10 rows:\")\n",
    "display(df_demographic.head(10))\n",
    "print(\"\\nLast 10 rows:\")\n",
    "display(df_demographic.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a5550",
   "metadata": {},
   "source": [
    "### 5.3 Biometric Dataset - First and Last 10 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a39ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>bio_age_5_17</th>\n",
       "      <th>bio_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>Mahendragarh</td>\n",
       "      <td>123029</td>\n",
       "      <td>280</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Madhepura</td>\n",
       "      <td>852121</td>\n",
       "      <td>144</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Punch</td>\n",
       "      <td>185101</td>\n",
       "      <td>643</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>Bhojpur</td>\n",
       "      <td>802158</td>\n",
       "      <td>256</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Madurai</td>\n",
       "      <td>625514</td>\n",
       "      <td>271</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Ratnagiri</td>\n",
       "      <td>416702</td>\n",
       "      <td>155</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Anand</td>\n",
       "      <td>388130</td>\n",
       "      <td>75</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Gandhinagar</td>\n",
       "      <td>382421</td>\n",
       "      <td>192</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Dhenkanal</td>\n",
       "      <td>759025</td>\n",
       "      <td>122</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01-03-2025</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Valsad</td>\n",
       "      <td>396055</td>\n",
       "      <td>67</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date              state      district  pincode  bio_age_5_17  \\\n",
       "0  01-03-2025            Haryana  Mahendragarh   123029           280   \n",
       "1  01-03-2025              Bihar     Madhepura   852121           144   \n",
       "2  01-03-2025  Jammu and Kashmir         Punch   185101           643   \n",
       "3  01-03-2025              Bihar       Bhojpur   802158           256   \n",
       "4  01-03-2025         Tamil Nadu       Madurai   625514           271   \n",
       "5  01-03-2025        Maharashtra     Ratnagiri   416702           155   \n",
       "6  01-03-2025            Gujarat         Anand   388130            75   \n",
       "7  01-03-2025            Gujarat   Gandhinagar   382421           192   \n",
       "8  01-03-2025             Odisha     Dhenkanal   759025           122   \n",
       "9  01-03-2025            Gujarat        Valsad   396055            67   \n",
       "\n",
       "   bio_age_17_  \n",
       "0          577  \n",
       "1          369  \n",
       "2         1091  \n",
       "3          980  \n",
       "4          815  \n",
       "5          529  \n",
       "6          143  \n",
       "7          298  \n",
       "8          214  \n",
       "9           85  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Last 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>bio_age_5_17</th>\n",
       "      <th>bio_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1861098</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>690535</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861099</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>690548</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861100</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>680667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861101</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>682001</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861102</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>682013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861103</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>682020</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861104</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>682022</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861105</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>682023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861106</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>682025</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861107</th>\n",
       "      <td>07-11-2025</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Ernakulam</td>\n",
       "      <td>682026</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date   state   district  pincode  bio_age_5_17  bio_age_17_\n",
       "1861098  07-11-2025  Kerala  Alappuzha   690535             3            4\n",
       "1861099  07-11-2025  Kerala  Alappuzha   690548             0            3\n",
       "1861100  07-11-2025  Kerala  Ernakulam   680667             0            1\n",
       "1861101  07-11-2025  Kerala  Ernakulam   682001             2            8\n",
       "1861102  07-11-2025  Kerala  Ernakulam   682013             1            1\n",
       "1861103  07-11-2025  Kerala  Ernakulam   682020             1            6\n",
       "1861104  07-11-2025  Kerala  Ernakulam   682022             1            0\n",
       "1861105  07-11-2025  Kerala  Ernakulam   682023             0            1\n",
       "1861106  07-11-2025  Kerala  Ernakulam   682025             3            6\n",
       "1861107  07-11-2025  Kerala  Ernakulam   682026             1            3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"First 10 rows:\")\n",
    "display(df_biometric.head(10))\n",
    "print(\"\\nLast 10 rows:\")\n",
    "display(df_biometric.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86da38b",
   "metadata": {},
   "source": [
    "## 6. Missing Values and Duplicates Analysis\n",
    "\n",
    "### 6.1 Missing Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6305c50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENROLMENT - MISSING VALUES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "✓ No missing values found!\n",
      "\n",
      "Total missing values: 0\n",
      "Percentage of missing values: 0.0000%\n",
      "\n",
      "================================================================================\n",
      "DEMOGRAPHIC - MISSING VALUES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "✓ No missing values found!\n",
      "\n",
      "Total missing values: 0\n",
      "Percentage of missing values: 0.0000%\n",
      "\n",
      "================================================================================\n",
      "BIOMETRIC - MISSING VALUES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "✓ No missing values found!\n",
      "\n",
      "Total missing values: 0\n",
      "Percentage of missing values: 0.0000%\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_values(df, dataset_name):\n",
    "    \"\"\"Analyze missing values in a dataset\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"{dataset_name.upper()} - MISSING VALUES ANALYSIS\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    missing_count = df.isnull().sum()\n",
    "    missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Column': missing_count.index,\n",
    "        'Missing_Count': missing_count.values,\n",
    "        'Missing_Percentage': missing_percent.values\n",
    "    })\n",
    "    missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "    \n",
    "    if len(missing_df) == 0:\n",
    "        print(\"\\n✓ No missing values found!\")\n",
    "    else:\n",
    "        print(f\"\\nColumns with missing values:\")\n",
    "        display(missing_df)\n",
    "    \n",
    "    print(f\"\\nTotal missing values: {df.isnull().sum().sum():,}\")\n",
    "    print(f\"Percentage of missing values: {(df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100:.4f}%\")\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "# Analyze missing values for all datasets\n",
    "missing_enrolment = analyze_missing_values(df_enrolment, \"Enrolment\")\n",
    "missing_demographic = analyze_missing_values(df_demographic, \"Demographic\")\n",
    "missing_biometric = analyze_missing_values(df_biometric, \"Biometric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcffb05",
   "metadata": {},
   "source": [
    "### 6.2 Duplicate Rows Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ada145a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENROLMENT - DUPLICATE ROWS CHECK\n",
      "================================================================================\n",
      "\n",
      "Total rows: 1,006,029\n",
      "Duplicate rows: 22,957\n",
      "Duplicate percentage: 2.2819%\n",
      "Unique rows: 983,072\n",
      "\n",
      "⚠ Warning: Found 22,957 duplicate rows!\n",
      "\n",
      "Sample duplicate rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359389</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>144041</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359390</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>144101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359391</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>144102</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359392</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>144418</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359393</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>144419</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359394</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>144702</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359395</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Jalandhar</td>\n",
       "      <td>144801</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359396</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Kapurthala</td>\n",
       "      <td>144401</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359397</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Kapurthala</td>\n",
       "      <td>144601</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359398</th>\n",
       "      <td>13-10-2025</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>Kapurthala</td>\n",
       "      <td>144804</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date   state    district  pincode  age_0_5  age_5_17  \\\n",
       "359389  13-10-2025  Punjab   Jalandhar   144041        2         1   \n",
       "359390  13-10-2025  Punjab   Jalandhar   144101        1         0   \n",
       "359391  13-10-2025  Punjab   Jalandhar   144102        2         0   \n",
       "359392  13-10-2025  Punjab   Jalandhar   144418        1         0   \n",
       "359393  13-10-2025  Punjab   Jalandhar   144419        1         0   \n",
       "359394  13-10-2025  Punjab   Jalandhar   144702        1         1   \n",
       "359395  13-10-2025  Punjab   Jalandhar   144801        0         1   \n",
       "359396  13-10-2025  Punjab  Kapurthala   144401        5         1   \n",
       "359397  13-10-2025  Punjab  Kapurthala   144601        4         2   \n",
       "359398  13-10-2025  Punjab  Kapurthala   144804        2         0   \n",
       "\n",
       "        age_18_greater  \n",
       "359389               0  \n",
       "359390               0  \n",
       "359391               0  \n",
       "359392               0  \n",
       "359393               0  \n",
       "359394               0  \n",
       "359395               0  \n",
       "359396               1  \n",
       "359397               2  \n",
       "359398               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DEMOGRAPHIC - DUPLICATE ROWS CHECK\n",
      "================================================================================\n",
      "\n",
      "Total rows: 2,071,700\n",
      "Duplicate rows: 473,601\n",
      "Duplicate percentage: 22.8605%\n",
      "Unique rows: 1,598,099\n",
      "\n",
      "⚠ Warning: Found 473,601 duplicate rows!\n",
      "\n",
      "Sample duplicate rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113325</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belagavi</td>\n",
       "      <td>591313</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113326</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belagavi</td>\n",
       "      <td>591315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113327</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belagavi</td>\n",
       "      <td>591316</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113328</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>590009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113329</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>591101</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113330</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>591106</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113331</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>591113</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113332</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>591115</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113333</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>591118</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113334</th>\n",
       "      <td>18-10-2025</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Belgaum</td>\n",
       "      <td>591121</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date      state  district  pincode  demo_age_5_17  demo_age_17_\n",
       "113325  18-10-2025  Karnataka  Belagavi   591313              0             1\n",
       "113326  18-10-2025  Karnataka  Belagavi   591315              0             1\n",
       "113327  18-10-2025  Karnataka  Belagavi   591316              0             1\n",
       "113328  18-10-2025  Karnataka   Belgaum   590009              0             1\n",
       "113329  18-10-2025  Karnataka   Belgaum   591101              1             6\n",
       "113330  18-10-2025  Karnataka   Belgaum   591106              1             5\n",
       "113331  18-10-2025  Karnataka   Belgaum   591113              0             2\n",
       "113332  18-10-2025  Karnataka   Belgaum   591115              1             3\n",
       "113333  18-10-2025  Karnataka   Belgaum   591118              2             2\n",
       "113334  18-10-2025  Karnataka   Belgaum   591121              0             6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BIOMETRIC - DUPLICATE ROWS CHECK\n",
      "================================================================================\n",
      "\n",
      "Total rows: 1,861,108\n",
      "Duplicate rows: 94,896\n",
      "Duplicate percentage: 5.0989%\n",
      "Unique rows: 1,766,212\n",
      "\n",
      "⚠ Warning: Found 94,896 duplicate rows!\n",
      "\n",
      "Sample duplicate rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>district</th>\n",
       "      <th>pincode</th>\n",
       "      <th>bio_age_5_17</th>\n",
       "      <th>bio_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109994</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Kondagaon</td>\n",
       "      <td>494229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109995</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Kondagaon</td>\n",
       "      <td>494230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109996</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Korba</td>\n",
       "      <td>495119</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109997</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Korba</td>\n",
       "      <td>495446</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109998</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Korba</td>\n",
       "      <td>495674</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109999</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Korba</td>\n",
       "      <td>495683</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110000</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Kondagaon</td>\n",
       "      <td>494229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110001</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Kondagaon</td>\n",
       "      <td>494230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110002</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Korba</td>\n",
       "      <td>495119</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110003</th>\n",
       "      <td>01-09-2025</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>Korba</td>\n",
       "      <td>495446</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date         state   district  pincode  bio_age_5_17  \\\n",
       "109994  01-09-2025  Chhattisgarh  Kondagaon   494229             0   \n",
       "109995  01-09-2025  Chhattisgarh  Kondagaon   494230             1   \n",
       "109996  01-09-2025  Chhattisgarh      Korba   495119             5   \n",
       "109997  01-09-2025  Chhattisgarh      Korba   495446             0   \n",
       "109998  01-09-2025  Chhattisgarh      Korba   495674            10   \n",
       "109999  01-09-2025  Chhattisgarh      Korba   495683             0   \n",
       "110000  01-09-2025  Chhattisgarh  Kondagaon   494229             0   \n",
       "110001  01-09-2025  Chhattisgarh  Kondagaon   494230             1   \n",
       "110002  01-09-2025  Chhattisgarh      Korba   495119             5   \n",
       "110003  01-09-2025  Chhattisgarh      Korba   495446             0   \n",
       "\n",
       "        bio_age_17_  \n",
       "109994            1  \n",
       "109995            0  \n",
       "109996           35  \n",
       "109997           16  \n",
       "109998           34  \n",
       "109999            3  \n",
       "110000            1  \n",
       "110001            0  \n",
       "110002           35  \n",
       "110003           16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_duplicates(df, dataset_name):\n",
    "    \"\"\"Check for duplicate rows in a dataset\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"{dataset_name.upper()} - DUPLICATE ROWS CHECK\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    duplicate_percent = (duplicate_count / total_rows) * 100\n",
    "    \n",
    "    print(f\"\\nTotal rows: {total_rows:,}\")\n",
    "    print(f\"Duplicate rows: {duplicate_count:,}\")\n",
    "    print(f\"Duplicate percentage: {duplicate_percent:.4f}%\")\n",
    "    print(f\"Unique rows: {total_rows - duplicate_count:,}\")\n",
    "    \n",
    "    if duplicate_count > 0:\n",
    "        print(f\"\\n⚠ Warning: Found {duplicate_count:,} duplicate rows!\")\n",
    "        print(\"\\nSample duplicate rows:\")\n",
    "        display(df[df.duplicated(keep=False)].head(10))\n",
    "    else:\n",
    "        print(\"\\n✓ No duplicate rows found!\")\n",
    "    \n",
    "    return duplicate_count\n",
    "\n",
    "# Check duplicates for all datasets\n",
    "dup_enrolment = check_duplicates(df_enrolment, \"Enrolment\")\n",
    "dup_demographic = check_duplicates(df_demographic, \"Demographic\")\n",
    "dup_biometric = check_duplicates(df_biometric, \"Biometric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8186c",
   "metadata": {},
   "source": [
    "## 7. Statistical Summary\n",
    "\n",
    "### 7.1 Enrolment Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c65a111c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENROLMENT DATASET - STATISTICAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Descriptive statistics for numerical columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pincode</th>\n",
       "      <th>age_0_5</th>\n",
       "      <th>age_5_17</th>\n",
       "      <th>age_18_greater</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1006029.00</td>\n",
       "      <td>1006029.00</td>\n",
       "      <td>1006029.00</td>\n",
       "      <td>1006029.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>518641.45</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>205635.97</td>\n",
       "      <td>17.54</td>\n",
       "      <td>14.37</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>363641.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>517417.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>700104.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>855456.00</td>\n",
       "      <td>2688.00</td>\n",
       "      <td>1812.00</td>\n",
       "      <td>855.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pincode    age_0_5   age_5_17  age_18_greater\n",
       "count 1006029.00 1006029.00 1006029.00      1006029.00\n",
       "mean   518641.45       3.53       1.71            0.17\n",
       "std    205635.97      17.54      14.37            3.22\n",
       "min    100000.00       0.00       0.00            0.00\n",
       "25%    363641.00       1.00       0.00            0.00\n",
       "50%    517417.00       2.00       0.00            0.00\n",
       "75%    700104.00       3.00       1.00            0.00\n",
       "max    855456.00    2688.00    1812.00          855.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional statistics:\n",
      "Median values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pincode          517417.00\n",
       "age_0_5               2.00\n",
       "age_5_17              0.00\n",
       "age_18_greater        0.00\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard Deviation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pincode          205635.97\n",
       "age_0_5              17.54\n",
       "age_5_17             14.37\n",
       "age_18_greater        3.22\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ENROLMENT DATASET - STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDescriptive statistics for numerical columns:\")\n",
    "display(df_enrolment.describe())\n",
    "\n",
    "print(\"\\nAdditional statistics:\")\n",
    "print(f\"Median values:\")\n",
    "display(df_enrolment.median(numeric_only=True))\n",
    "print(f\"\\nStandard Deviation:\")\n",
    "display(df_enrolment.std(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f36f33",
   "metadata": {},
   "source": [
    "### 7.2 Demographic Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82850700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEMOGRAPHIC DATASET - STATISTICAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Descriptive statistics for numerical columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pincode</th>\n",
       "      <th>demo_age_5_17</th>\n",
       "      <th>demo_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2071700.00</td>\n",
       "      <td>2071700.00</td>\n",
       "      <td>2071700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>527831.78</td>\n",
       "      <td>2.35</td>\n",
       "      <td>21.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>197293.32</td>\n",
       "      <td>14.90</td>\n",
       "      <td>125.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>396469.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>524322.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>695507.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>855456.00</td>\n",
       "      <td>2690.00</td>\n",
       "      <td>16166.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pincode  demo_age_5_17  demo_age_17_\n",
       "count 2071700.00     2071700.00    2071700.00\n",
       "mean   527831.78           2.35         21.45\n",
       "std    197293.32          14.90        125.25\n",
       "min    100000.00           0.00          0.00\n",
       "25%    396469.00           0.00          2.00\n",
       "50%    524322.00           1.00          6.00\n",
       "75%    695507.00           2.00         15.00\n",
       "max    855456.00        2690.00      16166.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional statistics:\n",
      "Median values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pincode         524322.00\n",
       "demo_age_5_17        1.00\n",
       "demo_age_17_         6.00\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard Deviation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pincode         197293.32\n",
       "demo_age_5_17       14.90\n",
       "demo_age_17_       125.25\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DEMOGRAPHIC DATASET - STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDescriptive statistics for numerical columns:\")\n",
    "display(df_demographic.describe())\n",
    "\n",
    "print(\"\\nAdditional statistics:\")\n",
    "print(f\"Median values:\")\n",
    "display(df_demographic.median(numeric_only=True))\n",
    "print(f\"\\nStandard Deviation:\")\n",
    "display(df_demographic.std(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c127f",
   "metadata": {},
   "source": [
    "### 7.3 Biometric Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1bab7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BIOMETRIC DATASET - STATISTICAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Descriptive statistics for numerical columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pincode</th>\n",
       "      <th>bio_age_5_17</th>\n",
       "      <th>bio_age_17_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1861108.00</td>\n",
       "      <td>1861108.00</td>\n",
       "      <td>1861108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>521761.17</td>\n",
       "      <td>18.39</td>\n",
       "      <td>19.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>198162.68</td>\n",
       "      <td>83.70</td>\n",
       "      <td>88.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>110001.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>391175.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>522401.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>686636.25</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>855456.00</td>\n",
       "      <td>8002.00</td>\n",
       "      <td>7625.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pincode  bio_age_5_17  bio_age_17_\n",
       "count 1861108.00    1861108.00   1861108.00\n",
       "mean   521761.17         18.39        19.09\n",
       "std    198162.68         83.70        88.07\n",
       "min    110001.00          0.00         0.00\n",
       "25%    391175.00          1.00         1.00\n",
       "50%    522401.00          3.00         4.00\n",
       "75%    686636.25         11.00        10.00\n",
       "max    855456.00       8002.00      7625.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional statistics:\n",
      "Median values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pincode        522401.00\n",
       "bio_age_5_17        3.00\n",
       "bio_age_17_         4.00\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard Deviation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pincode        198162.68\n",
       "bio_age_5_17       83.70\n",
       "bio_age_17_        88.07\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BIOMETRIC DATASET - STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nDescriptive statistics for numerical columns:\")\n",
    "display(df_biometric.describe())\n",
    "\n",
    "print(\"\\nAdditional statistics:\")\n",
    "print(f\"Median values:\")\n",
    "display(df_biometric.median(numeric_only=True))\n",
    "print(f\"\\nStandard Deviation:\")\n",
    "display(df_biometric.std(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab7aa2",
   "metadata": {},
   "source": [
    "## 8. Date Range Analysis\n",
    "\n",
    "Analyzing the temporal coverage of each dataset to understand the time period of data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b167f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENROLMENT - DATE RANGE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Date column found!\n",
      "Earliest date: 2025-01-04 00:00:00\n",
      "Latest date: 2025-12-11 00:00:00\n",
      "Date range span: 341 days\n",
      "\n",
      "Number of unique dates: 30\n",
      "Number of records per date (average): 33534.30\n",
      "\n",
      "⚠ Warning: 682,238 invalid/missing dates found\n",
      "\n",
      "Top 10 dates by record count:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-02-11    18080\n",
       "2025-09-09    16789\n",
       "2025-08-09    16768\n",
       "2025-10-09    16518\n",
       "2025-12-09    16107\n",
       "2025-01-09    15971\n",
       "2025-11-09    15950\n",
       "2025-05-11    15745\n",
       "2025-02-09    15622\n",
       "2025-03-09    15330\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DEMOGRAPHIC - DATE RANGE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Date column found!\n",
      "Earliest date: 2025-01-03 00:00:00\n",
      "Latest date: 2025-12-12 00:00:00\n",
      "Date range span: 343 days\n",
      "\n",
      "Number of unique dates: 41\n",
      "Number of records per date (average): 50529.27\n",
      "\n",
      "⚠ Warning: 1,187,968 invalid/missing dates found\n",
      "\n",
      "Top 10 dates by record count:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-12-12    34568\n",
       "2025-04-12    32603\n",
       "2025-08-12    31944\n",
       "2025-03-12    31316\n",
       "2025-06-11    28891\n",
       "2025-10-11    28828\n",
       "2025-08-11    28250\n",
       "2025-11-12    28144\n",
       "2025-04-11    26470\n",
       "2025-08-09    26109\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BIOMETRIC - DATE RANGE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Date column found!\n",
      "Earliest date: 2025-01-03 00:00:00\n",
      "Latest date: 2025-12-12 00:00:00\n",
      "Date range span: 343 days\n",
      "\n",
      "Number of unique dates: 41\n",
      "Number of records per date (average): 45392.88\n",
      "\n",
      "⚠ Warning: 944,100 invalid/missing dates found\n",
      "\n",
      "Top 10 dates by record count:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "2025-02-12    24529\n",
       "2025-01-11    24192\n",
       "2025-12-11    24169\n",
       "2025-09-12    23932\n",
       "2025-05-12    23869\n",
       "2025-07-11    23856\n",
       "2025-11-12    23830\n",
       "2025-12-12    23778\n",
       "2025-06-12    23773\n",
       "2025-04-12    23740\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def analyze_date_range(df, dataset_name):\n",
    "    \"\"\"Analyze date range in a dataset\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"{dataset_name.upper()} - DATE RANGE ANALYSIS\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    if 'date' in df.columns:\n",
    "        # Convert to datetime\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        \n",
    "        print(f\"\\nDate column found!\")\n",
    "        print(f\"Earliest date: {df['date'].min()}\")\n",
    "        print(f\"Latest date: {df['date'].max()}\")\n",
    "        print(f\"Date range span: {(df['date'].max() - df['date'].min()).days} days\")\n",
    "        print(f\"\\nNumber of unique dates: {df['date'].nunique():,}\")\n",
    "        print(f\"Number of records per date (average): {len(df) / df['date'].nunique():.2f}\")\n",
    "        \n",
    "        # Check for any invalid dates\n",
    "        invalid_dates = df['date'].isnull().sum()\n",
    "        if invalid_dates > 0:\n",
    "            print(f\"\\n⚠ Warning: {invalid_dates:,} invalid/missing dates found\")\n",
    "        else:\n",
    "            print(f\"\\n✓ All dates are valid\")\n",
    "        \n",
    "        # Show date distribution\n",
    "        print(f\"\\nTop 10 dates by record count:\")\n",
    "        date_counts = df['date'].value_counts().head(10)\n",
    "        display(date_counts)\n",
    "    else:\n",
    "        print(\"\\n⚠ No 'date' column found in dataset\")\n",
    "\n",
    "# Analyze date ranges for all datasets\n",
    "analyze_date_range(df_enrolment, \"Enrolment\")\n",
    "analyze_date_range(df_demographic, \"Demographic\")\n",
    "analyze_date_range(df_biometric, \"Biometric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe6dc4",
   "metadata": {},
   "source": [
    "## 9. Categorical Columns Analysis\n",
    "\n",
    "Analyzing unique counts for categorical columns (state, district, pincode) to understand geographical coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c31d9f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENROLMENT - CATEGORICAL COLUMNS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "STATE:\n",
      "  Unique values: 55\n",
      "  Most common values:\n",
      "    1. Uttar Pradesh: 110,369 records (10.97%)\n",
      "    2. Tamil Nadu: 92,552 records (9.20%)\n",
      "    3. Maharashtra: 77,191 records (7.67%)\n",
      "    4. West Bengal: 76,519 records (7.61%)\n",
      "    5. Karnataka: 70,198 records (6.98%)\n",
      "    6. Andhra Pradesh: 65,658 records (6.53%)\n",
      "    7. Bihar: 60,567 records (6.02%)\n",
      "    8. Rajasthan: 56,159 records (5.58%)\n",
      "    9. Madhya Pradesh: 50,225 records (4.99%)\n",
      "    10. Gujarat: 46,624 records (4.63%)\n",
      "\n",
      "DISTRICT:\n",
      "  Unique values: 985\n",
      "  Most common values:\n",
      "    1. Pune: 6,663 records (0.66%)\n",
      "    2. North 24 Parganas: 6,488 records (0.64%)\n",
      "    3. Barddhaman: 5,362 records (0.53%)\n",
      "    4. Bengaluru: 5,305 records (0.53%)\n",
      "    5. Hyderabad: 4,984 records (0.50%)\n",
      "    6. Malappuram: 4,700 records (0.47%)\n",
      "    7. Jaipur: 4,670 records (0.46%)\n",
      "    8. Murshidabad: 4,562 records (0.45%)\n",
      "    9. South 24 Parganas: 4,559 records (0.45%)\n",
      "    10. K.v. Rangareddy: 4,550 records (0.45%)\n",
      "\n",
      "PINCODE:\n",
      "  Unique values: 19,463\n",
      "  Most common values:\n",
      "    1. 500055: 274 records (0.03%)\n",
      "    2. 500018: 267 records (0.03%)\n",
      "    3. 500005: 247 records (0.02%)\n",
      "    4. 110053: 219 records (0.02%)\n",
      "    5. 431001: 216 records (0.02%)\n",
      "    6. 743329: 214 records (0.02%)\n",
      "    7. 244102: 211 records (0.02%)\n",
      "    8. 831002: 207 records (0.02%)\n",
      "    9. 713143: 202 records (0.02%)\n",
      "    10. 853204: 198 records (0.02%)\n",
      "\n",
      "================================================================================\n",
      "DEMOGRAPHIC - CATEGORICAL COLUMNS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "STATE:\n",
      "  Unique values: 65\n",
      "  Most common values:\n",
      "    1. Andhra Pradesh: 207,687 records (10.02%)\n",
      "    2. Tamil Nadu: 196,857 records (9.50%)\n",
      "    3. West Bengal: 168,623 records (8.14%)\n",
      "    4. Uttar Pradesh: 167,889 records (8.10%)\n",
      "    5. Maharashtra: 162,242 records (7.83%)\n",
      "    6. Karnataka: 153,957 records (7.43%)\n",
      "    7. Kerala: 105,515 records (5.09%)\n",
      "    8. Bihar: 97,621 records (4.71%)\n",
      "    9. Gujarat: 96,399 records (4.65%)\n",
      "    10. Odisha: 92,143 records (4.45%)\n",
      "\n",
      "DISTRICT:\n",
      "  Unique values: 983\n",
      "  Most common values:\n",
      "    1. North 24 Parganas: 12,994 records (0.63%)\n",
      "    2. Pune: 12,450 records (0.60%)\n",
      "    3. Barddhaman: 12,349 records (0.60%)\n",
      "    4. East Godavari: 12,186 records (0.59%)\n",
      "    5. Thrissur: 12,097 records (0.58%)\n",
      "    6. Karimnagar: 10,045 records (0.48%)\n",
      "    7. Hyderabad: 10,010 records (0.48%)\n",
      "    8. West Godavari: 10,007 records (0.48%)\n",
      "    9. Ernakulam: 9,895 records (0.48%)\n",
      "    10. Warangal: 9,857 records (0.48%)\n",
      "\n",
      "PINCODE:\n",
      "  Unique values: 19,742\n",
      "  Most common values:\n",
      "    1. 533464: 488 records (0.02%)\n",
      "    2. 500055: 474 records (0.02%)\n",
      "    3. 500018: 424 records (0.02%)\n",
      "    4. 491888: 412 records (0.02%)\n",
      "    5. 509105: 401 records (0.02%)\n",
      "    6. 713130: 397 records (0.02%)\n",
      "    7. 506164: 397 records (0.02%)\n",
      "    8. 507111: 397 records (0.02%)\n",
      "    9. 509130: 393 records (0.02%)\n",
      "    10. 743329: 392 records (0.02%)\n",
      "\n",
      "================================================================================\n",
      "BIOMETRIC - CATEGORICAL COLUMNS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "STATE:\n",
      "  Unique values: 57\n",
      "  Most common values:\n",
      "    1. Tamil Nadu: 184,568 records (9.92%)\n",
      "    2. Andhra Pradesh: 172,034 records (9.24%)\n",
      "    3. Uttar Pradesh: 155,242 records (8.34%)\n",
      "    4. Maharashtra: 151,104 records (8.12%)\n",
      "    5. Karnataka: 141,227 records (7.59%)\n",
      "    6. West Bengal: 130,735 records (7.02%)\n",
      "    7. Kerala: 98,511 records (5.29%)\n",
      "    8. Gujarat: 89,531 records (4.81%)\n",
      "    9. Odisha: 86,476 records (4.65%)\n",
      "    10. Bihar: 83,398 records (4.48%)\n",
      "\n",
      "DISTRICT:\n",
      "  Unique values: 974\n",
      "  Most common values:\n",
      "    1. Pune: 11,586 records (0.62%)\n",
      "    2. Thrissur: 11,165 records (0.60%)\n",
      "    3. East Godavari: 10,647 records (0.57%)\n",
      "    4. North 24 Parganas: 10,595 records (0.57%)\n",
      "    5. Barddhaman: 10,545 records (0.57%)\n",
      "    6. Warangal: 9,976 records (0.54%)\n",
      "    7. Palakkad: 9,605 records (0.52%)\n",
      "    8. Karimnagar: 9,514 records (0.51%)\n",
      "    9. Hyderabad: 9,422 records (0.51%)\n",
      "    10. Ernakulam: 9,113 records (0.49%)\n",
      "\n",
      "PINCODE:\n",
      "  Unique values: 19,707\n",
      "  Most common values:\n",
      "    1. 500055: 474 records (0.03%)\n",
      "    2. 500018: 436 records (0.02%)\n",
      "    3. 500087: 406 records (0.02%)\n",
      "    4. 500090: 377 records (0.02%)\n",
      "    5. 450661: 359 records (0.02%)\n",
      "    6. 605106: 358 records (0.02%)\n",
      "    7. 500067: 353 records (0.02%)\n",
      "    8. 509340: 353 records (0.02%)\n",
      "    9. 533464: 353 records (0.02%)\n",
      "    10. 506006: 345 records (0.02%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_categorical_columns(df, dataset_name):\n",
    "    \"\"\"Analyze categorical columns in a dataset\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"{dataset_name.upper()} - CATEGORICAL COLUMNS ANALYSIS\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    categorical_cols = ['state', 'district', 'pincode']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\n{col.upper()}:\")\n",
    "            print(f\"  Unique values: {df[col].nunique():,}\")\n",
    "            print(f\"  Most common values:\")\n",
    "            top_values = df[col].value_counts().head(10)\n",
    "            for idx, (value, count) in enumerate(top_values.items(), 1):\n",
    "                print(f\"    {idx}. {value}: {count:,} records ({count/len(df)*100:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"\\n⚠ Column '{col}' not found in dataset\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Analyze categorical columns for all datasets\n",
    "analyze_categorical_columns(df_enrolment, \"Enrolment\")\n",
    "analyze_categorical_columns(df_demographic, \"Demographic\")\n",
    "analyze_categorical_columns(df_biometric, \"Biometric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f28127",
   "metadata": {},
   "source": [
    "## 10. Data Quality Checks\n",
    "\n",
    "Checking for data quality issues such as negative values, outliers, and inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ab9157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENROLMENT - DATA QUALITY CHECKS\n",
      "================================================================================\n",
      "\n",
      "Checking 4 numerical columns...\n",
      "\n",
      "1. NEGATIVE VALUES CHECK:\n",
      "  ✓ No negative values found\n",
      "\n",
      "2. OUTLIERS CHECK (IQR method):\n",
      "  age_0_5: 102,013 outliers (10.14%)\n",
      "    Range: [0.00, 2688.00]\n",
      "    Expected range: [-2.00, 6.00]\n",
      "  age_5_17: 135,765 outliers (13.50%)\n",
      "    Range: [0.00, 1812.00]\n",
      "    Expected range: [-1.50, 2.50]\n",
      "  age_18_greater: 40,225 outliers (4.00%)\n",
      "    Range: [0.00, 855.00]\n",
      "    Expected range: [0.00, 0.00]\n",
      "\n",
      "3. ZERO VALUES CHECK:\n",
      "  age_0_5: 115,243 zeros (11.46%)\n",
      "  age_5_17: 556,737 zeros (55.34%)\n",
      "  age_18_greater: 965,804 zeros (96.00%)\n",
      "\n",
      "4. EXTREME VALUES (Bottom and Top 1%):\n",
      "  pincode:\n",
      "    1st percentile: 123023.00\n",
      "    99th percentile: 851128.00\n",
      "  age_0_5:\n",
      "    1st percentile: 0.00\n",
      "    99th percentile: 23.00\n",
      "  age_5_17:\n",
      "    1st percentile: 0.00\n",
      "    99th percentile: 14.00\n",
      "  age_18_greater:\n",
      "    1st percentile: 0.00\n",
      "    99th percentile: 2.00\n",
      "\n",
      "================================================================================\n",
      "DEMOGRAPHIC - DATA QUALITY CHECKS\n",
      "================================================================================\n",
      "\n",
      "Checking 3 numerical columns...\n",
      "\n",
      "1. NEGATIVE VALUES CHECK:\n",
      "  ✓ No negative values found\n",
      "\n",
      "2. OUTLIERS CHECK (IQR method):\n",
      "  demo_age_5_17: 147,428 outliers (7.12%)\n",
      "    Range: [0.00, 2690.00]\n",
      "    Expected range: [-3.00, 5.00]\n",
      "  demo_age_17_: 217,379 outliers (10.49%)\n",
      "    Range: [0.00, 16166.00]\n",
      "    Expected range: [-17.50, 34.50]\n",
      "\n",
      "3. ZERO VALUES CHECK:\n",
      "  demo_age_5_17: 996,464 zeros (48.10%)\n",
      "  demo_age_17_: 41,810 zeros (2.02%)\n",
      "\n",
      "4. EXTREME VALUES (Bottom and Top 1%):\n",
      "  pincode:\n",
      "    1st percentile: 125004.00\n",
      "    99th percentile: 848125.00\n",
      "  demo_age_5_17:\n",
      "    1st percentile: 0.00\n",
      "    99th percentile: 22.00\n",
      "  demo_age_17_:\n",
      "    1st percentile: 0.00\n",
      "    99th percentile: 226.00\n",
      "\n",
      "================================================================================\n",
      "BIOMETRIC - DATA QUALITY CHECKS\n",
      "================================================================================\n",
      "\n",
      "Checking 3 numerical columns...\n",
      "\n",
      "1. NEGATIVE VALUES CHECK:\n",
      "  ✓ No negative values found\n",
      "\n",
      "2. OUTLIERS CHECK (IQR method):\n",
      "  bio_age_5_17: 207,522 outliers (11.15%)\n",
      "    Range: [0.00, 8002.00]\n",
      "    Expected range: [-14.00, 26.00]\n",
      "  bio_age_17_: 216,868 outliers (11.65%)\n",
      "    Range: [0.00, 7625.00]\n",
      "    Expected range: [-12.50, 23.50]\n",
      "\n",
      "3. ZERO VALUES CHECK:\n",
      "  bio_age_5_17: 287,670 zeros (15.46%)\n",
      "  bio_age_17_: 196,095 zeros (10.54%)\n",
      "\n",
      "4. EXTREME VALUES (Bottom and Top 1%):\n",
      "  pincode:\n",
      "    1st percentile: 125005.00\n",
      "    99th percentile: 848102.00\n",
      "  bio_age_5_17:\n",
      "    1st percentile: 0.00\n",
      "    99th percentile: 298.00\n",
      "  bio_age_17_:\n",
      "    1st percentile: 0.00\n",
      "    99th percentile: 324.00\n"
     ]
    }
   ],
   "source": [
    "def check_data_quality(df, dataset_name):\n",
    "    \"\"\"Check for data quality issues\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"{dataset_name.upper()} - DATA QUALITY CHECKS\")\n",
    "    print('=' * 80)\n",
    "    \n",
    "    # Get numerical columns (excluding date if present)\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    if not numerical_cols:\n",
    "        print(\"\\n⚠ No numerical columns found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nChecking {len(numerical_cols)} numerical columns...\")\n",
    "    \n",
    "    # Check for negative values\n",
    "    print(\"\\n1. NEGATIVE VALUES CHECK:\")\n",
    "    negative_found = False\n",
    "    for col in numerical_cols:\n",
    "        negative_count = (df[col] < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            negative_found = True\n",
    "            print(f\"  ⚠ {col}: {negative_count:,} negative values ({negative_count/len(df)*100:.4f}%)\")\n",
    "    if not negative_found:\n",
    "        print(\"  ✓ No negative values found\")\n",
    "    \n",
    "    # Check for outliers using IQR method\n",
    "    print(\"\\n2. OUTLIERS CHECK (IQR method):\")\n",
    "    for col in numerical_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
    "        if outliers > 0:\n",
    "            print(f\"  {col}: {outliers:,} outliers ({outliers/len(df)*100:.2f}%)\")\n",
    "            print(f\"    Range: [{df[col].min():.2f}, {df[col].max():.2f}]\")\n",
    "            print(f\"    Expected range: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "    \n",
    "    # Check for zero values\n",
    "    print(\"\\n3. ZERO VALUES CHECK:\")\n",
    "    for col in numerical_cols:\n",
    "        zero_count = (df[col] == 0).sum()\n",
    "        if zero_count > 0:\n",
    "            print(f\"  {col}: {zero_count:,} zeros ({zero_count/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Check for extreme values (top and bottom 1%)\n",
    "    print(\"\\n4. EXTREME VALUES (Bottom and Top 1%):\")\n",
    "    for col in numerical_cols:\n",
    "        bottom_1_percent = df[col].quantile(0.01)\n",
    "        top_99_percent = df[col].quantile(0.99)\n",
    "        print(f\"  {col}:\")\n",
    "        print(f\"    1st percentile: {bottom_1_percent:.2f}\")\n",
    "        print(f\"    99th percentile: {top_99_percent:.2f}\")\n",
    "\n",
    "# Check data quality for all datasets\n",
    "check_data_quality(df_enrolment, \"Enrolment\")\n",
    "check_data_quality(df_demographic, \"Demographic\")\n",
    "check_data_quality(df_biometric, \"Biometric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979a2a4",
   "metadata": {},
   "source": [
    "## 11. Initial Insights and Data Distribution Summary\n",
    "\n",
    "Key findings from the exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c9d9cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INITIAL INSIGHTS AND DATA DISTRIBUTION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📊 DATASET OVERVIEW:\n",
      "1. Enrolment Dataset: 1,006,029 rows × 7 columns\n",
      "2. Demographic Dataset: 2,071,700 rows × 6 columns\n",
      "3. Biometric Dataset: 1,861,108 rows × 6 columns\n",
      "\n",
      "📅 TEMPORAL COVERAGE:\n",
      "Enrolment: 2025-01-04 00:00:00 to 2025-12-11 00:00:00\n",
      "Demographic: 2025-01-03 00:00:00 to 2025-12-12 00:00:00\n",
      "Biometric: 2025-01-03 00:00:00 to 2025-12-12 00:00:00\n",
      "\n",
      "🌍 GEOGRAPHICAL COVERAGE:\n",
      "State: Enrolment: 55 | Demographic: 65 | Biometric: 57\n",
      "District: Enrolment: 985 | Demographic: 983 | Biometric: 974\n",
      "Pincode: Enrolment: 19,463 | Demographic: 19,742 | Biometric: 19,707\n",
      "\n",
      "📈 AGE GROUP DISTRIBUTIONS:\n",
      "\n",
      "Enrolment Dataset Age Groups:\n",
      "  age_0_5: Total = 3,546,965, Mean = 3.53\n",
      "  age_5_17: Total = 1,720,384, Mean = 1.71\n",
      "  age_18_greater: Total = 168,353, Mean = 0.17\n",
      "\n",
      "Demographic Dataset Age Groups:\n",
      "  demo_age_5_17: Total = 4,863,424, Mean = 2.35\n",
      "  demo_age_17_: Total = 44,431,763, Mean = 21.45\n",
      "\n",
      "Biometric Dataset Age Groups:\n",
      "  bio_age_5_17: Total = 34,226,855, Mean = 18.39\n",
      "  bio_age_17_: Total = 35,536,240, Mean = 19.09\n",
      "\n",
      "✅ DATA COMPLETENESS:\n",
      "Enrolment missing values: 682,238 (9.6878%)\n",
      "Demographic missing values: 1,187,968 (9.5571%)\n",
      "Biometric missing values: 944,100 (8.4546%)\n",
      "\n",
      "🔄 DUPLICATE RECORDS:\n",
      "Enrolment duplicates: 385,118\n",
      "Demographic duplicates: 823,227\n",
      "Biometric duplicates: 331,623\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"INITIAL INSIGHTS AND DATA DISTRIBUTION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n📊 DATASET OVERVIEW:\")\n",
    "print(f\"1. Enrolment Dataset: {df_enrolment.shape[0]:,} rows × {df_enrolment.shape[1]} columns\")\n",
    "print(f\"2. Demographic Dataset: {df_demographic.shape[0]:,} rows × {df_demographic.shape[1]} columns\")\n",
    "print(f\"3. Biometric Dataset: {df_biometric.shape[0]:,} rows × {df_biometric.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n📅 TEMPORAL COVERAGE:\")\n",
    "if 'date' in df_enrolment.columns:\n",
    "    print(f\"Enrolment: {df_enrolment['date'].min()} to {df_enrolment['date'].max()}\")\n",
    "if 'date' in df_demographic.columns:\n",
    "    print(f\"Demographic: {df_demographic['date'].min()} to {df_demographic['date'].max()}\")\n",
    "if 'date' in df_biometric.columns:\n",
    "    print(f\"Biometric: {df_biometric['date'].min()} to {df_biometric['date'].max()}\")\n",
    "\n",
    "print(\"\\n🌍 GEOGRAPHICAL COVERAGE:\")\n",
    "geo_cols = ['state', 'district', 'pincode']\n",
    "for col in geo_cols:\n",
    "    counts = []\n",
    "    if col in df_enrolment.columns:\n",
    "        counts.append(f\"Enrolment: {df_enrolment[col].nunique():,}\")\n",
    "    if col in df_demographic.columns:\n",
    "        counts.append(f\"Demographic: {df_demographic[col].nunique():,}\")\n",
    "    if col in df_biometric.columns:\n",
    "        counts.append(f\"Biometric: {df_biometric[col].nunique():,}\")\n",
    "    print(f\"{col.capitalize()}: {' | '.join(counts)}\")\n",
    "\n",
    "print(\"\\n📈 AGE GROUP DISTRIBUTIONS:\")\n",
    "print(\"\\nEnrolment Dataset Age Groups:\")\n",
    "age_cols_enrol = [col for col in df_enrolment.columns if 'age' in col.lower()]\n",
    "for col in age_cols_enrol:\n",
    "    if df_enrolment[col].dtype in [np.int64, np.float64]:\n",
    "        print(f\"  {col}: Total = {df_enrolment[col].sum():,.0f}, Mean = {df_enrolment[col].mean():.2f}\")\n",
    "\n",
    "print(\"\\nDemographic Dataset Age Groups:\")\n",
    "age_cols_demo = [col for col in df_demographic.columns if 'age' in col.lower()]\n",
    "for col in age_cols_demo:\n",
    "    if df_demographic[col].dtype in [np.int64, np.float64]:\n",
    "        print(f\"  {col}: Total = {df_demographic[col].sum():,.0f}, Mean = {df_demographic[col].mean():.2f}\")\n",
    "\n",
    "print(\"\\nBiometric Dataset Age Groups:\")\n",
    "age_cols_bio = [col for col in df_biometric.columns if 'age' in col.lower()]\n",
    "for col in age_cols_bio:\n",
    "    if df_biometric[col].dtype in [np.int64, np.float64]:\n",
    "        print(f\"  {col}: Total = {df_biometric[col].sum():,.0f}, Mean = {df_biometric[col].mean():.2f}\")\n",
    "\n",
    "print(\"\\n✅ DATA COMPLETENESS:\")\n",
    "print(f\"Enrolment missing values: {df_enrolment.isnull().sum().sum():,} ({(df_enrolment.isnull().sum().sum() / (df_enrolment.shape[0] * df_enrolment.shape[1])) * 100:.4f}%)\")\n",
    "print(f\"Demographic missing values: {df_demographic.isnull().sum().sum():,} ({(df_demographic.isnull().sum().sum() / (df_demographic.shape[0] * df_demographic.shape[1])) * 100:.4f}%)\")\n",
    "print(f\"Biometric missing values: {df_biometric.isnull().sum().sum():,} ({(df_biometric.isnull().sum().sum() / (df_biometric.shape[0] * df_biometric.shape[1])) * 100:.4f}%)\")\n",
    "\n",
    "print(\"\\n🔄 DUPLICATE RECORDS:\")\n",
    "print(f\"Enrolment duplicates: {df_enrolment.duplicated().sum():,}\")\n",
    "print(f\"Demographic duplicates: {df_demographic.duplicated().sum():,}\")\n",
    "print(f\"Biometric duplicates: {df_biometric.duplicated().sum():,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda75ab",
   "metadata": {},
   "source": [
    "## 12. Save Data Summary Metadata\n",
    "\n",
    "Creating a comprehensive summary CSV file with metadata from all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baba6e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "METADATA SUMMARY\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Total_Rows</th>\n",
       "      <th>Total_Columns</th>\n",
       "      <th>Memory_Usage_MB</th>\n",
       "      <th>Missing_Values</th>\n",
       "      <th>Missing_Percentage</th>\n",
       "      <th>Duplicate_Rows</th>\n",
       "      <th>Duplicate_Percentage</th>\n",
       "      <th>Date_Start</th>\n",
       "      <th>Date_End</th>\n",
       "      <th>Unique_Dates</th>\n",
       "      <th>Unique_State</th>\n",
       "      <th>Unique_District</th>\n",
       "      <th>Unique_Pincode</th>\n",
       "      <th>Numerical_Columns</th>\n",
       "      <th>age_0_5_Total</th>\n",
       "      <th>age_0_5_Mean</th>\n",
       "      <th>age_0_5_Std</th>\n",
       "      <th>age_5_17_Total</th>\n",
       "      <th>age_5_17_Mean</th>\n",
       "      <th>age_5_17_Std</th>\n",
       "      <th>age_18_greater_Total</th>\n",
       "      <th>age_18_greater_Mean</th>\n",
       "      <th>age_18_greater_Std</th>\n",
       "      <th>demo_age_5_17_Total</th>\n",
       "      <th>demo_age_5_17_Mean</th>\n",
       "      <th>demo_age_5_17_Std</th>\n",
       "      <th>demo_age_17__Total</th>\n",
       "      <th>demo_age_17__Mean</th>\n",
       "      <th>demo_age_17__Std</th>\n",
       "      <th>bio_age_5_17_Total</th>\n",
       "      <th>bio_age_5_17_Mean</th>\n",
       "      <th>bio_age_5_17_Std</th>\n",
       "      <th>bio_age_17__Total</th>\n",
       "      <th>bio_age_17__Mean</th>\n",
       "      <th>bio_age_17__Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enrolment</td>\n",
       "      <td>1006029</td>\n",
       "      <td>7</td>\n",
       "      <td>150.20</td>\n",
       "      <td>682238</td>\n",
       "      <td>9.69</td>\n",
       "      <td>385118</td>\n",
       "      <td>38.28</td>\n",
       "      <td>2025-01-04</td>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>985</td>\n",
       "      <td>19463</td>\n",
       "      <td>4</td>\n",
       "      <td>3546965.00</td>\n",
       "      <td>3.53</td>\n",
       "      <td>17.54</td>\n",
       "      <td>1720384.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>14.37</td>\n",
       "      <td>168353.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Demographic</td>\n",
       "      <td>2071700</td>\n",
       "      <td>6</td>\n",
       "      <td>294.08</td>\n",
       "      <td>1187968</td>\n",
       "      <td>9.56</td>\n",
       "      <td>823227</td>\n",
       "      <td>39.74</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>41</td>\n",
       "      <td>65</td>\n",
       "      <td>983</td>\n",
       "      <td>19742</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4863424.00</td>\n",
       "      <td>2.35</td>\n",
       "      <td>14.90</td>\n",
       "      <td>44431763.00</td>\n",
       "      <td>21.45</td>\n",
       "      <td>125.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biometric</td>\n",
       "      <td>1861108</td>\n",
       "      <td>6</td>\n",
       "      <td>263.96</td>\n",
       "      <td>944100</td>\n",
       "      <td>8.45</td>\n",
       "      <td>331623</td>\n",
       "      <td>17.82</td>\n",
       "      <td>2025-01-03</td>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>974</td>\n",
       "      <td>19707</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34226855.00</td>\n",
       "      <td>18.39</td>\n",
       "      <td>83.70</td>\n",
       "      <td>35536240.00</td>\n",
       "      <td>19.09</td>\n",
       "      <td>88.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset  Total_Rows  Total_Columns  Memory_Usage_MB  Missing_Values  \\\n",
       "0    Enrolment     1006029              7           150.20          682238   \n",
       "1  Demographic     2071700              6           294.08         1187968   \n",
       "2    Biometric     1861108              6           263.96          944100   \n",
       "\n",
       "   Missing_Percentage  Duplicate_Rows  Duplicate_Percentage Date_Start  \\\n",
       "0                9.69          385118                 38.28 2025-01-04   \n",
       "1                9.56          823227                 39.74 2025-01-03   \n",
       "2                8.45          331623                 17.82 2025-01-03   \n",
       "\n",
       "    Date_End  Unique_Dates  Unique_State  Unique_District  Unique_Pincode  \\\n",
       "0 2025-12-11            30            55              985           19463   \n",
       "1 2025-12-12            41            65              983           19742   \n",
       "2 2025-12-12            41            57              974           19707   \n",
       "\n",
       "   Numerical_Columns  age_0_5_Total  age_0_5_Mean  age_0_5_Std  \\\n",
       "0                  4     3546965.00          3.53        17.54   \n",
       "1                  3            NaN           NaN          NaN   \n",
       "2                  3            NaN           NaN          NaN   \n",
       "\n",
       "   age_5_17_Total  age_5_17_Mean  age_5_17_Std  age_18_greater_Total  \\\n",
       "0      1720384.00           1.71         14.37             168353.00   \n",
       "1             NaN            NaN           NaN                   NaN   \n",
       "2             NaN            NaN           NaN                   NaN   \n",
       "\n",
       "   age_18_greater_Mean  age_18_greater_Std  demo_age_5_17_Total  \\\n",
       "0                 0.17                3.22                  NaN   \n",
       "1                  NaN                 NaN           4863424.00   \n",
       "2                  NaN                 NaN                  NaN   \n",
       "\n",
       "   demo_age_5_17_Mean  demo_age_5_17_Std  demo_age_17__Total  \\\n",
       "0                 NaN                NaN                 NaN   \n",
       "1                2.35              14.90         44431763.00   \n",
       "2                 NaN                NaN                 NaN   \n",
       "\n",
       "   demo_age_17__Mean  demo_age_17__Std  bio_age_5_17_Total  bio_age_5_17_Mean  \\\n",
       "0                NaN               NaN                 NaN                NaN   \n",
       "1              21.45            125.25                 NaN                NaN   \n",
       "2                NaN               NaN         34226855.00              18.39   \n",
       "\n",
       "   bio_age_5_17_Std  bio_age_17__Total  bio_age_17__Mean  bio_age_17__Std  \n",
       "0               NaN                NaN               NaN              NaN  \n",
       "1               NaN                NaN               NaN              NaN  \n",
       "2             83.70        35536240.00             19.09            88.07  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Metadata summary saved to: /home/prince/Desktop/UIDAI Hackathon/outputs/results/data_summary.csv\n"
     ]
    }
   ],
   "source": [
    "def create_metadata_summary():\n",
    "    \"\"\"Create a comprehensive metadata summary for all datasets\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    # Helper function to extract metadata\n",
    "    def extract_metadata(df, dataset_name):\n",
    "        metadata = {\n",
    "            'Dataset': dataset_name,\n",
    "            'Total_Rows': df.shape[0],\n",
    "            'Total_Columns': df.shape[1],\n",
    "            'Memory_Usage_MB': df.memory_usage(deep=True).sum() / 1024**2,\n",
    "            'Missing_Values': df.isnull().sum().sum(),\n",
    "            'Missing_Percentage': (df.isnull().sum().sum() / (df.shape[0] * df.shape[1])) * 100,\n",
    "            'Duplicate_Rows': df.duplicated().sum(),\n",
    "            'Duplicate_Percentage': (df.duplicated().sum() / df.shape[0]) * 100,\n",
    "        }\n",
    "        \n",
    "        # Add date range if date column exists\n",
    "        if 'date' in df.columns:\n",
    "            metadata['Date_Start'] = df['date'].min()\n",
    "            metadata['Date_End'] = df['date'].max()\n",
    "            metadata['Unique_Dates'] = df['date'].nunique()\n",
    "        else:\n",
    "            metadata['Date_Start'] = None\n",
    "            metadata['Date_End'] = None\n",
    "            metadata['Unique_Dates'] = None\n",
    "        \n",
    "        # Add geographical info\n",
    "        for col in ['state', 'district', 'pincode']:\n",
    "            if col in df.columns:\n",
    "                metadata[f'Unique_{col.capitalize()}'] = df[col].nunique()\n",
    "            else:\n",
    "                metadata[f'Unique_{col.capitalize()}'] = None\n",
    "        \n",
    "        # Add numerical column statistics\n",
    "        numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        metadata['Numerical_Columns'] = len(numerical_cols)\n",
    "        \n",
    "        # Add age group totals if present\n",
    "        age_cols = [col for col in df.columns if 'age' in col.lower()]\n",
    "        for col in age_cols:\n",
    "            if df[col].dtype in [np.int64, np.float64]:\n",
    "                metadata[f'{col}_Total'] = df[col].sum()\n",
    "                metadata[f'{col}_Mean'] = df[col].mean()\n",
    "                metadata[f'{col}_Std'] = df[col].std()\n",
    "        \n",
    "        return metadata\n",
    "    \n",
    "    # Extract metadata for all datasets\n",
    "    summary_data.append(extract_metadata(df_enrolment, 'Enrolment'))\n",
    "    summary_data.append(extract_metadata(df_demographic, 'Demographic'))\n",
    "    summary_data.append(extract_metadata(df_biometric, 'Biometric'))\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "# Create and save metadata summary\n",
    "metadata_summary = create_metadata_summary()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"METADATA SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "display(metadata_summary)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = OUTPUT_PATH / 'data_summary.csv'\n",
    "metadata_summary.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Metadata summary saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f060d",
   "metadata": {},
   "source": [
    "## 13. Conclusion\n",
    "\n",
    "This exploratory data analysis has provided a comprehensive overview of the three Aadhaar datasets:\n",
    "\n",
    "### Key Findings:\n",
    "1. **Data Volume**: Successfully loaded and consolidated multiple CSV files from each dataset\n",
    "2. **Data Quality**: Assessed missing values, duplicates, and data consistency\n",
    "3. **Temporal Coverage**: Analyzed date ranges to understand the time period of data collection\n",
    "4. **Geographical Coverage**: Examined the distribution across states, districts, and pincodes\n",
    "5. **Age Group Analysis**: Reviewed enrolment and update patterns across different age groups\n",
    "\n",
    "### Next Steps:\n",
    "- Feature engineering based on insights from this exploration\n",
    "- Time series analysis for trend identification\n",
    "- Predictive modeling for Aadhaar update demand forecasting\n",
    "- Visualization of key patterns and trends\n",
    "\n",
    "The cleaned metadata has been saved to `outputs/results/data_summary.csv` for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b84ccb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d50cb131",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
